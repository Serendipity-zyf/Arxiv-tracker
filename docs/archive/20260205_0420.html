<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-02-05 04:20</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260205_0420</div>
    <div class="row"><div class="card">
<div class="title">Measuring Agents in Production</div>
<div class="meta-line">Authors: Melissa Z. Pan, Negar Arabzadeh, Riccardo Cogo, Yuxuan Zhu, Alexander Xiong, Lakshya A Agrawal, Huanzhi Mao, Emma Shen, Sid Pallerla, Liana Patel, Shu Liu, Tianneng Shi, Xiaoyuan Liu, Jared Quincy Davis, Emmanuele Lacavalla, Alessandro Basile, Shuyi Yang, Paul Castro, Daniel Kang, Joseph E. Gonzalez, Koushik Sen, Dawn Song, Ion Stoica, Matei Zaharia, Marquita Ellis</div>
<div class="meta-line">First: 2025-12-02T16:45:10+00:00 · Latest: 2026-02-03T18:06:26+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.04123v3">Abs</a> · <a href="https://arxiv.org/pdf/2512.04123v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">LLM-based agents already operate in production across many industries, yet we lack an understanding of what technical methods make deployments successful. We present the first systematic study of Measuring Agents in Production, MAP, using first-hand data from agent developers. We conducted 20 case studies via in-depth interviews and surveyed 306 practitioners across 26 domains. We investigate why organizations build agents, how they build them, how they evaluate them, and their top development challenges. Our study finds that production agents are built using simple, controllable approaches: 68% execute at most 10 steps before human intervention, 70% rely on prompting off-the-shelf models instead of weight tuning, and 74% depend primarily on human evaluation. Reliability (consistent correct behavior over time) remains the top development challenge, which practitioners currently address through systems-level design. MAP documents the current state of production agents, providing the research community with visibility into deployment realities and under-explored research avenues.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the lack of understanding of successful technical methods for deploying LLM-based agents in real-world settings, this study presents MAP, the first systematic investigation using first-hand data. The method involved conducting 20 in-depth case study interviews and surveying 306 practitioners across 26 industries to analyze why organizations build agents, how they build and evaluate them, and their key challenges. Key experimental findings reveal that production agents predominantly use simple, controllable approaches: 68% execute ≤10 steps before human intervention, 70% rely on prompting off-the-shelf models without weight tuning, and 74% depend primarily on human evaluation, with reliability being the top challenge addressed through systems-level design.</div>
<div class="mono" style="margin-top:8px">鉴于缺乏对跨行业生产中运行的基于LLM智能体成功技术方法的系统性理解，研究人员利用一手数据开展了首次研究（MAP）。他们通过20个深度案例访谈并调查了26个领域的306名从业者，探究组织构建智能体的原因、构建与评估方式及其主要挑战。研究发现生产环境中的智能体主要采用简单可控的方法：68%在执行不超过10步后即需人工干预，70%依赖提示现成模型而非权重调优，74%主要依靠人工评估。可靠性成为首要开发挑战，从业者目前通过系统级设计予以应对。</div>
</details>
</div>
<div class="card">
<div class="title">Ontology-to-tools compilation for executable semantic constraint enforcement in LLM agents</div>
<div class="meta-line">Authors: Xiaochi Zhou, Patrick Bulter, Changxuan Yang, Simon D. Rihm, Thitikarn Angkanaporn, Jethro Akroyd, Sebastian Mosbach, Markus Kraft</div>
<div class="meta-line">First: 2026-02-03T12:03:26+00:00 · Latest: 2026-02-03T12:03:26+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03439v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03439v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We introduce ontology-to-tools compilation as a proof-of-principle mechanism for coupling large language models (LLMs) with formal domain knowledge. Within The World Avatar (TWA), ontological specifications are compiled into executable tool interfaces that LLM-based agents must use to create and modify knowledge graph instances, enforcing semantic constraints during generation rather than through post-hoc validation. Extending TWA&#x27;s semantic agent composition framework, the Model Context Protocol (MCP) and associated agents are integral components of the knowledge graph ecosystem, enabling structured interaction between generative models, symbolic constraints, and external resources. An agent-based workflow translates ontologies into ontology-aware tools and iteratively applies them to extract, validate, and repair structured knowledge from unstructured scientific text. Using metal-organic polyhedra synthesis literature as an illustrative case, we show how executable ontological semantics can guide LLM behaviour and reduce manual schema and prompt engineering, establishing a general paradigm for embedding formal knowledge into generative systems.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We introduce ontology-to-tools compilation as a proof-of-principle mechanism for coupling large language models (LLMs) with formal domain knowledge.</div>
</details>
</div>
<div class="card">
<div class="title">PACE: Pretrained Audio Continual Learning</div>
<div class="meta-line">Authors: Chang Li, Kanglei Zhou, Liyuan Wang</div>
<div class="meta-line">Venue: ICLR 2026</div>
<div class="meta-line">First: 2026-02-03T10:28:35+00:00 · Latest: 2026-02-03T10:28:35+00:00</div>
<div class="meta-line">Comments: Accepted at ICLR 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03355v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03355v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Audio is a fundamental modality for analyzing speech, music, and environmental sounds. Although pretrained audio models have significantly advanced audio understanding, they remain fragile in real-world settings where data distributions shift over time. In this work, we present the first systematic benchmark for audio continual learning (CL) with pretrained models (PTMs), together with a comprehensive analysis of its unique challenges. Unlike in vision, where parameter-efficient fine-tuning (PEFT) has proven effective for CL, directly transferring such strategies to audio leads to poor performance. This stems from a fundamental property of audio backbones: they focus on low-level spectral details rather than structured semantics, causing severe upstream-downstream misalignment. Through extensive empirical study, we identify analytic classifiers with first-session adaptation (FSA) as a promising direction, but also reveal two major limitations: representation saturation in coarse-grained scenarios and representation drift in fine-grained scenarios. To address these challenges, we propose PACE, a novel method that enhances FSA via a regularized analytic classifier and enables multi-session adaptation through adaptive subspace-orthogonal PEFT for improved semantic alignment. In addition, we introduce spectrogram-based boundary-aware perturbations to mitigate representation overlap and improve stability. Experiments on six diverse audio CL benchmarks demonstrate that PACE substantially outperforms state-of-the-art baselines, marking an important step toward robust and scalable audio continual learning with PTMs.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Audio is a fundamental modality for analyzing speech, music, and environmental sounds.</div>
</details>
</div>
<div class="card">
<div class="title">The Necessity of a Unified Framework for LLM-Based Agent Evaluation</div>
<div class="meta-line">Authors: Pengyu Zhu, Li Sun, Philip S. Yu, Sen Su</div>
<div class="meta-line">First: 2026-02-03T08:18:37+00:00 · Latest: 2026-02-03T08:18:37+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03238v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03238v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">With the advent of Large Language Models (LLMs), general-purpose agents have seen fundamental advancements. However, evaluating these agents presents unique challenges that distinguish them from static QA benchmarks. We observe that current agent benchmarks are heavily confounded by extraneous factors, including system prompts, toolset configurations, and environmental dynamics. Existing evaluations often rely on fragmented, researcher-specific frameworks where the prompt engineering for reasoning and tool usage varies significantly, making it difficult to attribute performance gains to the model itself. Additionally, the lack of standardized environmental data leads to untraceable errors and non-reproducible results. This lack of standardization introduces substantial unfairness and opacity into the field. We propose that a unified evaluation framework is essential for the rigorous advancement of agent evaluation. To this end, we introduce a proposal aimed at standardizing agent evaluation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>构建统一框架对基于LLM的智能体进行评价的必要性</div>
<div class="mono" style="margin-top:8px">随着大语言模型（LLMs）的出现，通用智能体取得了根本性突破。然而，评估这类智能体面临静态问答基准所不具备的独特挑战。我们发现当前智能体基准测试严重受系统提示词、工具集配置和环境动态等外部因素干扰。现有评估常采用碎片化且依赖研究者个人偏好的框架，其推理与工具使用的提示工程差异显著，导致性能提升难以归因于模型本身。此外，标准化环境数据的缺失造成错误难以追踪、结果无法复现。这种标准化缺失导致该领域存在严重的不公平性与不透明性。我们认为建立统一评估框架对严格推进智能体评估至关重要。为此，我们提出了一项旨在标准化智能体评估的提案。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">With the advent of Large Language Models (LLMs), general-purpose agents have seen fundamental advancements.</div>
</details>
</div>
<div class="card">
<div class="title">Understanding Multi-Agent LLM Frameworks: A Unified Benchmark and Experimental Analysis</div>
<div class="meta-line">Authors: Abdelghny Orogat, Ana Rostam, Essam Mansour</div>
<div class="meta-line">First: 2026-02-03T05:37:56+00:00 · Latest: 2026-02-03T05:37:56+00:00</div>
<div class="meta-line">Comments: 25 pages, 9 figures and 13 tables; introduces MAFBench unified multi-agent evaluation suite</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03128v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03128v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multi-agent LLM frameworks are widely used to accelerate the development of agent systems powered by large language models (LLMs). These frameworks impose distinct architectural structures that govern how agents interact, store information, and coordinate tasks. However, their impact on system performance remains poorly understood. This gap is critical, as architectural choices alone can induce order-of-magnitude differences in latency and throughput, as well as substantial variation in accuracy and scalability. Addressing this challenge requires (i) jointly evaluating multiple capabilities, such as orchestration overhead, memory behavior, planning, specialization, and coordination, and (ii) conducting these evaluations under controlled, framework-level conditions to isolate architectural effects. Existing benchmarks focus on individual capabilities and lack standardized framework-level evaluation. We address these limitations by (i) introducing an architectural taxonomy for systematically comparing multi-agent LLM frameworks along fundamental dimensions, and (ii) developing MAFBench, a unified evaluation suite that integrates existing benchmarks under a standardized execution pipeline. Using MAFBench, we conduct a controlled empirical study across several widely used frameworks. Our results show that framework-level design choices alone can increase latency by over 100x, reduce planning accuracy by up to 30%, and lower coordination success from above 90% to below 30%. Finally, we translate our findings into concrete architectural design principles and framework selection guidance, and outline promising future research directions.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Multi-agent LLM frameworks are widely used to accelerate the development of agent systems powered by large language models (LLMs).</div>
</details>
</div>
<div class="card">
<div class="title">Multi-Agent Teams Hold Experts Back</div>
<div class="meta-line">Authors: Aneesh Pappu, Batu El, Hancheng Cao, Carmelo di Nolfo, Yanchao Sun, Meng Cao, James Zou</div>
<div class="meta-line">First: 2026-02-01T04:34:36+00:00 · Latest: 2026-02-03T04:46:07+00:00</div>
<div class="meta-line">Comments: Preprint</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.01011v2">Abs</a> · <a href="https://arxiv.org/pdf/2602.01011v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Multi-agent LLM systems are increasingly deployed as autonomous collaborators, where agents interact freely rather than execute fixed, pre-specified workflows. In such settings, effective coordination cannot be fully designed in advance and must instead emerge through interaction. However, most prior work enforces coordination through fixed roles, workflows, or aggregation rules, leaving open the question of how well self-organizing teams perform when coordination is unconstrained. Drawing on organizational psychology, we study whether self-organizing LLM teams achieve strong synergy, where team performance matches or exceeds the best individual member. Across human-inspired and frontier ML benchmarks, we find that -- unlike human teams -- LLM teams consistently fail to match their expert agent&#x27;s performance, even when explicitly told who the expert is, incurring performance losses of up to 37.6%. Decomposing this failure, we show that expert leveraging, rather than identification, is the primary bottleneck. Conversational analysis reveals a tendency toward integrative compromise -- averaging expert and non-expert views rather than appropriately weighting expertise -- which increases with team size and correlates negatively with performance. Interestingly, this consensus-seeking behavior improves robustness to adversarial agents, suggesting a trade-off between alignment and effective expertise utilization. Our findings reveal a significant gap in the ability of self-organizing multi-agent teams to harness the collective expertise of their members.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Multi-agent LLM systems are increasingly deployed as autonomous collaborators, where agents interact freely rather than execute fixed, pre-specified workflows.</div>
</details>
</div>
<div class="card">
<div class="title">FedKRSO: Communication and Memory Efficient Federated Fine-Tuning of Large Language Models</div>
<div class="meta-line">Authors: Guohao Yang, Tongle Wu, Yuanxiong Guo, Ying Sun, Yanmin Gong</div>
<div class="meta-line">First: 2026-02-03T02:39:33+00:00 · Latest: 2026-02-03T02:39:33+00:00</div>
<div class="meta-line">Comments: Accepted by INFOCOM 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.03019v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.03019v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Fine-tuning is essential to adapt general-purpose large language models (LLMs) to domain-specific tasks. As a privacy-preserving framework to leverage decentralized data for collaborative model training, Federated Learning (FL) is gaining popularity in LLM fine-tuning, but remains challenging due to the high cost of transmitting full model parameters and computing full gradients on resource-constrained clients. While Parameter-Efficient Fine-Tuning (PEFT) methods are widely used in FL to reduce communication and memory costs, they often sacrifice model performance compared to FFT. This paper proposes FedKRSO (Federated $K$-Seed Random Subspace Optimization), a novel method that enables communication and memory efficient FFT of LLMs in federated settings. In FedKRSO, clients update the model within a shared set of random low-dimension subspaces generated by the server to save memory usage. Furthermore, instead of transmitting full model parameters in each FL round, clients send only the model update accumulators along the subspaces to the server, enabling efficient global model aggregation and dissemination. By using these strategies, FedKRSO can substantially reduce communication and memory overhead while overcoming the performance limitations of PEFT, closely approximating the performance of federated FFT. The convergence properties of FedKRSO are analyzed rigorously under general FL settings. Extensive experiments on the GLUE benchmark across diverse FL scenarios demonstrate that FedKRSO achieves both superior performance and low communication and memory overhead, paving the way towards on federated LLM fine-tuning at the resource-constrained edge.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Fine-tuning is essential to adapt general-purpose large language models (LLMs) to domain-specific tasks.</div>
</details>
</div>
<div class="card">
<div class="title">Natural Language Actor-Critic: Scalable Off-Policy Learning in Language Space</div>
<div class="meta-line">Authors: Joey Hong, Kang Liu, Zhan Ling, Jiecao Chen, Sergey Levine</div>
<div class="meta-line">First: 2025-12-04T09:21:44+00:00 · Latest: 2026-02-02T22:54:14+00:00</div>
<div class="meta-line">Comments: 21 pages, 4 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.04601v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.04601v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language model (LLM) agents -- LLMs that dynamically interact with an environment over long horizons -- have become an increasingly important area of research, enabling automation in complex tasks involving tool-use, web browsing, and dialogue with people. In the absence of expert demonstrations, training LLM agents has relied on policy gradient methods that optimize LLM policies with respect to an (often sparse) reward function. However, in long-horizon tasks with sparse rewards, learning from trajectory-level rewards can be noisy, leading to training that is unstable and has high sample complexity. Furthermore, policy improvement hinges on discovering better actions through exploration, which can be difficult when actions lie in natural language space. In this paper, we propose Natural Language Actor-Critic (NLAC), a novel actor-critic algorithm that trains LLM policies using a generative LLM critic that produces natural language rather than scalar values. This approach leverages the inherent strengths of LLMs to provide a richer and more actionable training signal; particularly, in tasks with large, open-ended action spaces, natural language explanations for why an action is suboptimal can be immensely useful for LLM policies to reason how to improve their actions, without relying on random exploration. Furthermore, our approach can be trained off-policy without policy gradients, offering a more data-efficient and stable alternative to existing on-policy methods. We present results on a mixture of reasoning, web browsing, and tool-use with dialogue tasks, demonstrating that NLAC shows promise in outperforming existing training approaches and offers a more scalable and stable training paradigm for LLM agents.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large language model (LLM) agents -- LLMs that dynamically interact with an environment over long horizons -- have become an increasingly important area of research, enabling automation in complex tasks involving tool-use, web browsing, and dialogue with people.</div>
</details>
</div>
<div class="card">
<div class="title">AutoSizer: Automatic Sizing of Analog and Mixed-Signal Circuits via Large Language Model (LLM) Agents</div>
<div class="meta-line">Authors: Xi Yu, Dmitrii Torbunov, Soumyajit Mandal, Yihui Ren</div>
<div class="meta-line">First: 2026-02-02T21:51:55+00:00 · Latest: 2026-02-02T21:51:55+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02849v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02849v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The design of Analog and Mixed-Signal (AMS) integrated circuits remains heavily reliant on expert knowledge, with transistor sizing a major bottleneck due to nonlinear behavior, high-dimensional design spaces, and strict performance constraints. Existing Electronic Design Automation (EDA) methods typically frame sizing as static black-box optimization, resulting in inefficient and less robust solutions. Although Large Language Models (LLMs) exhibit strong reasoning abilities, they are not suited for precise numerical optimization in AMS sizing. To address this gap, we propose AutoSizer, a reflective LLM-driven meta-optimization framework that unifies circuit understanding, adaptive search-space construction, and optimization orchestration in a closed loop. It employs a two-loop optimization framework, with an inner loop for circuit sizing and an outer loop that analyzes optimization dynamics and constraints to iteratively refine the search space from simulation feedback. We further introduce AMS-SizingBench, an open benchmark comprising 24 diverse AMS circuits in SKY130 CMOS technology, designed to evaluate adaptive optimization policies under realistic simulator-based constraints. AutoSizer experimentally achieves higher solution quality, faster convergence, and higher success rate across varying circuit difficulties, outperforming both traditional optimization methods and existing LLM-based agents.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The design of Analog and Mixed-Signal (AMS) integrated circuits remains heavily reliant on expert knowledge, with transistor sizing a major bottleneck due to nonlinear behavior, high-dimensional design spaces, and strict performance constraints.</div>
</details>
</div>
<div class="card">
<div class="title">From Task Solving to Robust Real-World Adaptation in LLM Agents</div>
<div class="meta-line">Authors: Pouya Pezeshkpour, Estevam Hruschka</div>
<div class="meta-line">First: 2026-02-02T20:10:40+00:00 · Latest: 2026-02-02T20:10:40+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02760v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02760v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models are increasingly deployed as specialized agents that plan, call tools, and take actions over extended horizons. Yet many existing evaluations assume a &quot;clean interface&quot; where dynamics are specified and stable, tools and sensors are reliable, and success is captured by a single explicit objective-often overestimating real-world readiness. In practice, agents face underspecified rules, unreliable signals, shifting environments, and implicit, multi-stakeholder goals. The challenge is therefore not just solving tasks, but adapting while solving: deciding what to trust, what is wanted, when to verify, and when to fall back or escalate. We stress-test deployment-relevant robustness under four operational circumstances: partial observability, dynamic environments, noisy signals, and dynamic agent state. We benchmark agentic LLMs in a grid-based game with a simple goal but long-horizon execution. Episodes violate clean-interface assumptions yet remain solvable, forcing agents to infer rules, pay for information, adapt to environmental and internal shifts, and act cautiously under noise. Across five state-of-the-art LLM agents, we find large gaps between nominal task-solving and deployment-like robustness. Performance generally degrades as grid size and horizon increase, but rankings are unstable: weaker models can beat stronger ones when strategy matches the uncertainty regime. Despite no explicit instruction, agents trade off completion, efficiency, and penalty avoidance, suggesting partial objective inference. Ablations and feature analyses reveal model-specific sensitivities and failure drivers, motivating work on verification, safe action selection, and objective inference under partial observability, noise, and non-stationarity.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large language models are increasingly deployed as specialized agents that plan, call tools, and take actions over extended horizons.</div>
</details>
</div>
<div class="card">
<div class="title">MARS: Modular Agent with Reflective Search for Automated AI Research</div>
<div class="meta-line">Authors: Jiefeng Chen, Bhavana Dalvi Mishra, Jaehyun Nam, Rui Meng, Tomas Pfister, Jinsung Yoon</div>
<div class="meta-line">First: 2026-02-02T19:00:03+00:00 · Latest: 2026-02-02T19:00:03+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02660v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02660v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Automating AI research differs from general software engineering due to computationally expensive evaluation (e.g., model training) and opaque performance attribution. Current LLM-based agents struggle here, often generating monolithic scripts that ignore execution costs and causal factors. We introduce MARS (Modular Agent with Reflective Search), a framework optimized for autonomous AI research. MARS relies on three pillars: (1) Budget-Aware Planning via cost-constrained Monte Carlo Tree Search (MCTS) to explicitly balance performance with execution expense; (2) Modular Construction, employing a &quot;Design-Decompose-Implement&quot; pipeline to manage complex research repositories; and (3) Comparative Reflective Memory, which addresses credit assignment by analyzing solution differences to distill high-signal insights. MARS achieves state-of-the-art performance among open-source frameworks on MLE-Bench under comparable settings, maintaining competitiveness with the global leaderboard&#x27;s top methods. Furthermore, the system exhibits qualitative &quot;Aha!&quot; moments, where 63% of all utilized lessons originate from cross-branch transfer, demonstrating that the agent effectively generalizes insights across search paths.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Automating AI research differs from general software engineering due to computationally expensive evaluation (e.g., model training) and opaque performance attribution.</div>
</details>
</div>
<div class="card">
<div class="title">Fat-Cat: Document-Driven Metacognitive Multi-Agent System for Complex Reasoning</div>
<div class="meta-line">Authors: Tong Yang, Yemin Wang, Chaoning Zhang, Aming Wu</div>
<div class="meta-line">First: 2026-02-02T15:12:13+00:00 · Latest: 2026-02-02T15:12:13+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02206v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02206v1">PDF</a> · <a href="https://github.com/answeryt/Fat-Cat">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The effectiveness of LLM-based agents is often limited not by model capacity alone, but by how efficiently contextual information is utilized at runtime. Existing agent frameworks rely on rigid, syntax-heavy state representations such as nested JSON, which require models to devote a substantial portion of their limited attention to syntactic processing rather than semantic reasoning. In this paper, we propose Fat-Cat, a document-driven agent architecture that improves the signal-to-noise ratio of state management. By integrating three key components: (1) a Semantic File System that represents agent state as Markdown documents aligned with common pre-training corpora, (2) a Textual Strategy Evolution module that accumulates task-solving knowledge without parameter updates, and (3) a Closed-Loop Watcher that monitors reasoning trajectories to reduce hallucinations. Extensive reasoning, retrieval, and coding benchmarks, Fat-Cat consistently improves agent performance. It enables the Kimi-k2 model to outperform the proprietary GPT-4o baseline on HotPotQA. Replacing the document-based state with JSON leads to performance drop, while empirically validating the critical necessity of document-driven state modeling over rigid syntax. The code is available at https://github.com/answeryt/Fat-Cat.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The effectiveness of LLM-based agents is often limited not by model capacity alone, but by how efficiently contextual information is utilized at runtime.</div>
</details>
</div>
<div class="card">
<div class="title">Constrained Process Maps for Multi-Agent Generative AI Workflows</div>
<div class="meta-line">Authors: Ananya Joshi, Michael Rudow</div>
<div class="meta-line">First: 2026-02-02T12:32:11+00:00 · Latest: 2026-02-02T12:32:11+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.02034v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.02034v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language model (LLM)-based agents are increasingly used to perform complex, multi-step workflows in regulated settings such as compliance and due diligence. However, many agentic architectures rely primarily on prompt engineering of a single agent, making it difficult to observe or compare how models handle uncertainty and coordination across interconnected decision stages and with human oversight. We introduce a multi-agent system formalized as a finite-horizon Markov Decision Process (MDP) with a directed acyclic structure. Each agent corresponds to a specific role or decision stage (e.g., content, business, or legal review in a compliance workflow), with predefined transitions representing task escalation or completion. Epistemic uncertainty is quantified at the agent level using Monte Carlo estimation, while system-level uncertainty is captured by the MDP&#x27;s termination in either an automated labeled state or a human-review state. We illustrate the approach through a case study in AI safety evaluation for self-harm detection, implemented as a multi-agent compliance system. Results demonstrate improvements over a single-agent baseline, including up to a 19\% increase in accuracy, up to an 85x reduction in required human review, and, in some configurations, reduced processing time.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向多智能体生成式AI工作流的约束流程映射</div>
<div class="mono" style="margin-top:8px">基于大语言模型（LLM）的智能体日益广泛地应用于合规性与尽职调查等受监管场景中的复杂多步骤工作流。然而，多数智能体架构主要依赖单一智能体的提示工程，难以观测或比较模型在相互关联的决策阶段间处理不确定性和协调机制的表现，亦难以评估人工监督效果。本文提出一种形式化为有限时域马尔可夫决策过程（MDP）的多智能体系统，其结构为有向无环图。每个智能体对应特定角色或决策阶段（如合规工作流中的内容审核、业务审核或法务审核），预定义转移路径代表任务升级或完成。通过蒙特卡洛估计在智能体层面量化认知不确定性，而系统级不确定性则通过MDP终止于自动标记状态或人工审核状态来表征。我们以自残检测的AI安全评估为案例，构建多智能体合规系统进行验证。结果表明：相较单智能体基线，该系统实现最高19%的准确率提升，人工审核需求降低达85倍，部分配置下处理时间亦有所缩减。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large language model (LLM)-based agents are increasingly used to perform complex, multi-step workflows in regulated settings such as compliance and due diligence.</div>
</details>
</div>
<div class="card">
<div class="title">ORCH: many analyses, one merge-a deterministic multi-agent orchestrator for discrete-choice reasoning with EMA-guided routing</div>
<div class="meta-line">Authors: Hanlin Zhou, Huah Yong Chan</div>
<div class="meta-line">First: 2026-02-02T08:27:58+00:00 · Latest: 2026-02-02T08:27:58+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.01797v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.01797v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent advances in large-scale language models (LLMs) have made multi-agent architectures attractive for challenging reasoning tasks. However, many existing systems rely on stochastic routing or ad-hoc heuristics, making their behavior difficult to reproduce and their decision process hard to interpret. We propose ORCH, a deterministic coordination framework for discrete-choice reasoning that orchestrates heterogeneous LLMs. ORCH follows a ``many analyses, one decision&#x27;&#x27; paradigm: multiple base models independently produce structured analyses, and a dedicated merge agent outputs the final choice. The framework uses fixed rules for task decomposition and answer aggregation, keeping the pipeline predictable, reproducible, and training-free. Determinism here refers to fixed routing and aggregation rules under a fixed evaluation protocol, rather than strict bit-level reproducibility across deployments. To exploit model complementarity, we optionally introduce an EMA-guided router that updates agent selection using historical accuracy, latency, or cost; since it relies on answer-based feedback, it is mainly intended for benchmarking, controlled evaluation, or delayed-feedback settings. Experiments on MMLU, MMLU-Pro, and GSM8K show that ORCH consistently outperforms single-model baselines and a majority-vote ensemble. On MMLU-Pro, ORCH improves accuracy by over 10 points compared to the strongest baseline, and on GSM8K it yields gains exceeding 50 points; McNemar tests confirm statistical significance. The EMA router provides an additional 0.7--2.0 point accuracy boost, and ablations show that both multi-agent collaboration and routing contribute substantially. Overall, ORCH offers a practical path toward controllable, interpretable, and deployment-ready LLM-based agent systems for discrete-choice reasoning.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Recent advances in large-scale language models (LLMs) have made multi-agent architectures attractive for challenging reasoning tasks.</div>
</details>
</div>
<div class="card">
<div class="title">TRIP-Bench: A Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios</div>
<div class="meta-line">Authors: Yuanzhe Shen, Zisu Huang, Zhengyuan Wang, Muzhao Tian, Zhengkang Guo, Chenyang Zhang, Shuaiyu Zhou, Zengjie Hu, Dailin Li, Jingwen Xu, Kaimin Wang, Wenhao Liu, Tianlong Li, Fengpeng Yue, Feng Hong, Cao Liu, Ke Zeng</div>
<div class="meta-line">First: 2026-02-02T05:43:08+00:00 · Latest: 2026-02-02T05:43:08+00:00</div>
<div class="meta-line">Comments: 40 pages, 6figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.01675v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.01675v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">As LLM-based agents are deployed in increasingly complex real-world settings, existing benchmarks underrepresent key challenges such as enforcing global constraints, coordinating multi-tool reasoning, and adapting to evolving user behavior over long, multi-turn interactions. To bridge this gap, we introduce \textbf{TRIP-Bench}, a long-horizon benchmark grounded in realistic travel-planning scenarios. TRIP-Bench leverages real-world data, offers 18 curated tools and 40+ travel requirements, and supports automated evaluation. It includes splits of varying difficulty; the hard split emphasizes long and ambiguous interactions, style shifts, feasibility changes, and iterative version revision. Dialogues span up to 15 user turns, can involve 150+ tool calls, and may exceed 200k tokens of context. Experiments show that even advanced models achieve at most 50\% success on the easy split, with performance dropping below 10\% on hard subsets. We further propose \textbf{GTPO}, an online multi-turn reinforcement learning method with specialized reward normalization and reward differencing. Applied to Qwen2.5-32B-Instruct, GTPO improves constraint satisfaction and interaction robustness, outperforming Gemini-3-Pro in our evaluation. We expect TRIP-Bench to advance practical long-horizon interactive agents, and GTPO to provide an effective online RL recipe for robust long-horizon training.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">As LLM-based agents are deployed in increasingly complex real-world settings, existing benchmarks underrepresent key challenges such as enforcing global constraints, coordinating multi-tool reasoning, and adapting to evolving user behavior over long, multi-turn interactions.</div>
</details>
</div>
<div class="card">
<div class="title">JudgeFlow: Agentic Workflow Optimization via Block Judge</div>
<div class="meta-line">Authors: Zihan Ma, Zhikai Zhao, Chuanbo Hua, Federico Berto, Jinkyoo Park</div>
<div class="meta-line">First: 2026-01-12T12:30:14+00:00 · Latest: 2026-02-02T04:22:18+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.07477v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.07477v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Optimizing LLM-based agentic workflows is challenging for scaling AI capabilities. Current methods rely on coarse, end-to-end evaluation signals and lack fine-grained signals on where to refine, often resulting in inefficient or low-impact modifications. To address these limitations, we propose JudgeFlow, an Evaluation-Judge-Optimization-Update pipeline. We incorporate reusable, configurable logic blocks into agentic workflows to capture fundamental forms of logic. On top of this abstraction, we design a dedicated Judge module that inspects execution traces particularly failed runs and assigns rank-based responsibility scores to problematic blocks. These fine-grained diagnostic signals are then leveraged by an LLM-based optimizer, which focuses modifications on the most problematic block in the workflow. Our approach improves sample efficiency, enhances interpretability through block-level diagnostics, and provides a scalable foundation for automating increasingly complex agentic workflows. We evaluate JudgeFlow on mathematical reasoning and code generation benchmarks, where JudgeFlow achieves superior performance and efficiency compared to existing methods.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>JudgeFlow：基于块级评估的智能体工作流优化</div>
<div class="mono" style="margin-top:8px">优化基于LLM的智能体工作流对扩展AI能力至关重要，但当前方法依赖粗粒度的端到端评估信号，缺乏细粒度优化指引，常导致低效或低价值修改。为此，我们提出JudgeFlow框架——采用评估-诊断-优化-更新的流程：首先将可复用、可配置的逻辑块嵌入工作流以捕获基础逻辑形态；基于此抽象层设计专用诊断模块，通过分析执行轨迹（特别是失败案例）为问题模块分配基于排名的责任分数；随后由基于LLM的优化器利用这些细粒度诊断信号，针对性修正工作流中最关键的模块。该方法显著提升样本效率，通过块级诊断增强可解释性，并为自动化复杂智能体工作流提供可扩展基础。在数学推理与代码生成基准测试中，JudgeFlow展现出优于现有方法的性能与效率。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Optimizing LLM-based agentic workflows is challenging for scaling AI capabilities.</div>
<div class="mono" style="margin-top:8px">针对现有LLM智能体工作流优化方法依赖粗粒度端到端评估信号、导致修改效率低下或效果不佳的问题，本研究提出了JudgeFlow方法。该方法在工作流中引入可复用逻辑块，并设计专用Judge模块分析执行轨迹（尤其是失败案例），为问题模块分配基于排名的责任分数；随后基于LLM的优化器聚焦修改责任分数最高的模块。在数学推理和代码生成基准测试中，JudgeFlow相比现有方法展现出更优的性能和样本效率。</div>
</details>
</div>
<div class="card">
<div class="title">TransportAgents: a multi-agents LLM framework for traffic accident severity prediction</div>
<div class="meta-line">Authors: Zhichao Yang, Jiashu He, Jinxuan Fan, Cirillo Cinzia</div>
<div class="meta-line">First: 2026-01-21T23:14:05+00:00 · Latest: 2026-02-02T04:18:37+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.15519v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.15519v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Accurate prediction of traffic crash severity is critical for improving emergency response and public safety planning. Although recent large language models (LLMs) exhibit strong reasoning capabilities, their single-agent architectures often struggle with heterogeneous, domain-specific crash data and tend to generate biased or unstable predictions. To address these limitations, this paper proposes TransportAgents, a hybrid multi-agent framework that integrates category-specific LLM reasoning with a multilayer perceptron (MLP) integration module. Each specialized agent focuses on a particular subset of traffic information, such as demographics, environmental context, or incident details, to produce intermediate severity assessments that are subsequently fused into a unified prediction. Extensive experiments on two complementary U.S. datasets, the Consumer Product Safety Risk Management System (CPSRMS) and the National Electronic Injury Surveillance System (NEISS), demonstrate that TransportAgents consistently outperforms both traditional machine learning and advanced LLM-based baselines. Across three representative backbones, including closed-source models such as GPT-3.5 and GPT-4o, as well as open-source models such as LLaMA-3.3, the framework exhibits strong robustness, scalability, and cross-dataset generalizability. A supplementary distributional analysis further shows that TransportAgents produces more balanced and well-calibrated severity predictions than standard single-agent LLM approaches, highlighting its interpretability and reliability for safety-critical decision support applications.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>交通智能体：基于多智能体大语言模型的交通事故严重程度预测框架</div>
<div class="mono" style="margin-top:8px">准确预测交通事故严重程度对提升应急响应与公共安全规划至关重要。尽管当前大语言模型（LLM）展现出强大的推理能力，但其单智能体架构常难以处理异构的领域特定事故数据，易产生有偏或不稳定的预测。为突破这些局限，本文提出TransportAgents混合多智能体框架，通过整合分类专属LLM推理模块与多层感知器（MLP）实现预测。该框架通过多智能体协作处理异构事故数据，提升预测准确性</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Accurate prediction of traffic crash severity is critical for improving emergency response and public safety planning.</div>
</details>
</div>
<div class="card">
<div class="title">When Is Rank-1 Enough? Geometry-Guided Initialization for Parameter-Efficient Fine-Tuning</div>
<div class="meta-line">Authors: Haoran Zhao, Soyeon Caren Han, Eduard Hovy</div>
<div class="meta-line">First: 2026-02-02T01:31:25+00:00 · Latest: 2026-02-02T01:31:25+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.01522v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.01522v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Parameter-efficient fine-tuning (PEFT) is a standard way to adapt multimodal large language models, yet extremely low-rank settings -- especially rank-1 LoRA -- are often unstable. We show that this instability is not solely due to limited capacity: in the rank-1 regime, optimization is highly sensitive to the update direction. Concretely, pretrained vision and text features form mismatched anisotropic regions, yielding a dominant &quot;gap&quot; direction that acts like a translation component and disproportionately steers early gradients under rank-1 constraints. Analyzing pretrained representations, we identify a modality-gap axis that dominates early gradient flow, while a random rank-1 initialization is unlikely to align with it, leading to weak gradients and training collapse. We propose Gap-Init, a geometry-aware initialization that aligns the rank-1 LoRA direction with an estimated modality-gap vector from a small calibration set, while keeping the initial LoRA update zero. Across multiple vision-language tasks and backbones, Gap-Init consistently stabilizes rank-1 training and can match or outperform strong rank-8 baselines. Our results suggest that at the extreme low-rank limit, initial alignment can matter as much as rank itself.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Parameter-efficient fine-tuning (PEFT) is a standard way to adapt multimodal large language models, yet extremely low-rank settings -- especially rank-1 LoRA -- are often unstable.</div>
</details>
</div>
<div class="card">
<div class="title">Workflow-R1: Group Sub-sequence Policy Optimization for Multi-turn Workflow Construction</div>
<div class="meta-line">Authors: Mingze Kong, Zikun Qu, Zhongquan Zhou, Pengyu Liang, Xiang Li, Zhiwei Shang, Zhi Hong, Kaiyu Huang, Zhiyong Wang, Zhongxiang Dai</div>
<div class="meta-line">First: 2026-02-01T12:44:59+00:00 · Latest: 2026-02-01T12:44:59+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.01202v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.01202v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The rapid evolution of agentic workflows has demonstrated strong performance of LLM-based agents in addressing complex reasoning tasks. However, existing workflow optimization methods typically formulate workflow synthesis as a static, one-shot code-centric generation problem. This paradigm imposes excessive constraints on the model&#x27;s coding capabilities and restricts the flexibility required for dynamic problem-solving. In this paper, we present Workflow-R1, a framework that reformulates workflow construction as a multi-turn, natural language-based sequential decision-making process. To resolve the optimization granularity mismatch inherent in such multi-turn interactions, we introduce Group Sub-sequence Policy Optimization (GSsPO). While explicitly tailored to align with the interleaved Think-Action dynamics of agentic reasoning, GSsPO fundamentally functions as a structure-aware RL algorithm generalizable to a broad class of multi-turn agentic sequential decision-making tasks. By recalibrating the optimization unit to the composite sub-sequence, specifically the atomic Think-Action cycle, it aligns gradient updates with the semantic boundaries of these interactions, ensuring robust learning in complex multi-turn reasoning tasks. Through extensive experiments on multiple QA benchmarks, Workflow-R1 outperforms competitive baselines, validating GSsPO as a generalized solution for sequential reasoning and establishing Workflow-R1 as a promising new paradigm for automated workflow optimization.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>工作流-R1：面向多轮工作流构建的组子序列策略优化</div>
<div class="mono" style="margin-top:8px">智能体工作流的快速发展彰显了基于LLM的智能体在处理复杂推理任务中的卓越性能。然而，现有工作流优化方法通常将工作流合成建模为静态、单次性的代码中心生成问题。这种范式过度约束模型的编码能力，限制了动态问题解决所需的灵活性。本文提出Workflow-R1框架，将工作流构建重构为基于自然语言的多轮序列决策过程。为解决多轮交互中固有的优化粒度不匹配问题，我们引入组子序列策略优化（GSsPO）。该算法虽明确适配智能体推理中思考-行动交替的动态特性，但本质上是一种可泛化至多轮智能体序列决策任务的结构感知强化学习算法。通过将优化单元重新校准至复合子序列（特别是原子化的思考-行动周期），其梯度更新与交互语义边界对齐，确保在复杂多轮推理任务中实现稳健学习。在多个QA基准测试中，Workflow-R1均超越基线模型，验证了GSsPO作为序列推理通用解决方案的有效性，同时确立了Workflow-R1作为自动化工作流优化的新型范式。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The rapid evolution of agentic workflows has demonstrated strong performance of LLM-based agents in addressing complex reasoning tasks.</div>
</details>
</div>
<div class="card">
<div class="title">AutoHealth: An Uncertainty-Aware Multi-Agent System for Autonomous Health Data Modeling</div>
<div class="meta-line">Authors: Tong Xia, Weibin Li, Gang Liu, Yong Li</div>
<div class="meta-line">First: 2026-02-01T07:50:15+00:00 · Latest: 2026-02-01T07:50:15+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.01078v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.01078v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">LLM-based agents have demonstrated strong potential for autonomous machine learning, yet their applicability to health data remains limited. Existing systems often struggle to generalize across heterogeneous health data modalities, rely heavily on predefined solution templates with insufficient adaptation to task-specific objectives, and largely overlook uncertainty estimation, which is essential for reliable decision-making in healthcare. To address these challenges, we propose \textit{AutoHealth}, a novel uncertainty-aware multi-agent system that autonomously models health data and assesses model reliability. \textit{AutoHealth} employs closed-loop coordination among five specialized agents to perform data exploration, task-conditioned model construction, training, and optimization, while jointly prioritizing predictive performance and uncertainty quantification. Beyond producing ready-to-use models, the system generates comprehensive reports to support trustworthy interpretation and risk-aware decision-making. To rigorously evaluate its effectiveness, we curate a challenging real-world benchmark comprising 17 tasks across diverse data modalities and learning settings. \textit{AutoHealth} completes all tasks and outperforms state-of-the-art baselines by 29.2\% in prediction performance and 50.2\% in uncertainty estimation.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>AutoHealth：一种面向自主健康数据建模的不确定性感知多智能体系统</div>
<div class="mono" style="margin-top:8px">基于大语言模型的智能体在自主机器学习领域展现出巨大潜力，但其在健康数据中的应用仍受限。现有系统常难以泛化至异构健康数据模态，过度依赖预定义解决方案模板而缺乏对任务特定目标的适应性，且普遍忽视对医疗可靠决策至关重要的不确定性估计。为应对这些挑战，我们提出\textit{AutoHealth}——一种新型不确定性感知多智能体系统，可自主建模健康数据并评估模型可靠性。该系统通过五个专业智能体的闭环协调，执行数据探索、任务条件化模型构建、训练与优化，同时兼顾预测性能与不确定性量化。除生成即用型模型外，系统还生成综合报告以支持可信解释与风险感知决策。为严格评估其效能，我们构建了包含17项跨模态学习任务的真实世界基准测试。\textit{AutoHealth} 成功完成所有任务，预测性能超越最先进基线29.2%，不确定性估计能力提升50.2%。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">LLM-based agents have demonstrated strong potential for autonomous machine learning, yet their applicability to health data remains limited.</div>
</details>
</div>
<div class="card">
<div class="title">Hypernetwork-Driven Low-Rank Adaptation Across Attention Heads</div>
<div class="meta-line">Authors: Nghiem T. Diep, Dung Le, Tuan Truong, Tan Dinh, Huy Nguyen, Nhat Ho</div>
<div class="meta-line">First: 2025-10-05T17:13:39+00:00 · Latest: 2026-01-31T22:34:25+00:00</div>
<div class="meta-line">Comments: Nghiem T. Diep, Dung Le, and Tuan Truong contributed equally to this work</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2510.04295v2">Abs</a> · <a href="https://arxiv.org/pdf/2510.04295v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Parameter-efficient fine-tuning (PEFT) has emerged as a powerful paradigm for adapting large-scale pre-trained models to downstream tasks with minimal additional parameters. Among PEFT methods, Low-Rank Adaptation (LoRA) stands out for its effectiveness by inserting trainable low-rank matrices into weight updates to enable efficient adaptation. However, when applied to multi-head self-attention, existing LoRA-based methods typically fine-tune each attention head independently, overlooking potential interactions and shared structure among heads. To address this limitation, we propose Hypernetwork-Driven Low-rank Adaptation (HyRA) that employs a hypernetwork to generate joint low-rank matrices for all attention heads within a layer. The shared generator promotes cross-head information sharing, helping low-rank modules avoid the redundant feature learning seen in traditional LoRA methods. Theoretically, our method achieves significantly better sample efficiency compared to standard LoRA. Empirically, we evaluate HyRA on a comprehensive suite of language and vision benchmarks. Our approach consistently outperforms existing parameter-efficient fine-tuning (PEFT) baselines across a wide range of tasks. Notably, in low-data regimes, HyRA achieves substantial improvements over LoRA, underscoring its practical sample efficiency and effectiveness in data-scarce scenarios.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Parameter-efficient fine-tuning (PEFT) has emerged as a powerful paradigm for adapting large-scale pre-trained models to downstream tasks with minimal additional parameters.</div>
</details>
</div>
<div class="card">
<div class="title">Synapse Compendium Aware Federated Knowledge Exchange for Tool Routed LLMs</div>
<div class="meta-line">Authors: Abhijit Chakraborty, Sandipan De, Yash Shah, Chahana Dahal, Vivek Gupta</div>
<div class="meta-line">First: 2026-01-31T21:43:48+00:00 · Latest: 2026-01-31T21:43:48+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.00911v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.00911v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Collaborative learning among LLM-based agents under federated learning faces challenges, including communication costs, heterogeneity in data, and tool-usage, limiting their effectiveness. We introduce Synapse, a framework that trains a shared global knowledge model of tool-usage behavior. Client agents with fixed LLMs learn tool-usage patterns locally, and transmit artifacts for federated aggregation through coordinators. A global tool compendium is updated and redistributed, enabling convergence toward stable tool selection. Synapse uses templated representations, embedding retrieval with LLM reranking, and adaptive masking to maintain utility while limiting information leakage. The framework supports heterogeneous data and quantifies performance improvements. Results show that Synapse improves tool-usage effectiveness and reduces communication overhead compared with weight or prompt-sharing approaches in multi-agent LLM systems.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>面向工具路由大语言模型的突触知识库感知联邦知识交换框架</div>
<div class="mono" style="margin-top:8px">联邦学习下基于大语言模型的智能体协同学习面临通信成本、数据异构性及工具使用差异等挑战，制约了系统效能。本文提出Synapse框架，通过训练共享的全局工具使用行为知识模型，使固定大语言模型的客户端智能体在本地学习工具使用模式，并通过协调器传输知识构件进行联邦聚合。该框架动态更新并分发全局工具知识库，推动系统向稳定工具选择收敛。Synapse采用模板化表示法、嵌入检索与大语言模型重排技术，结合自适应掩蔽机制，在保障实用性的同时限制信息泄露。该框架支持异构数据环境并量化性能提升，实验表明：相比权重或提示共享方案，Synapse在多智能体大语言模型系统中显著提升工具使用效能并降低通信开销。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Collaborative learning among LLM-based agents under federated learning faces challenges, including communication costs, heterogeneity in data, and tool-usage, limiting their effectiveness.</div>
<div class="mono" style="margin-top:8px">针对联邦学习中LLM智能体面临的通信成本高、数据与工具使用异构性等挑战，本研究提出Synapse框架。该方法训练共享的全局工具使用知识模型：固定LLM的客户端智能体在本地学习工具使用模式，通过协调器传输知识产物进行联邦聚合，并利用模板化表示、嵌入检索结合LLM重排序以及自适应掩码技术更新全局工具手册以限制信息泄露。实验结果证明，在多智能体LLM系统中，相比权重或提示共享方法，Synapse显著提升了工具使用效能并降低了通信开销。</div>
</details>
</div>
<div class="card">
<div class="title">Evolving Interpretable Constitutions for Multi-Agent Coordination</div>
<div class="meta-line">Authors: Ujwal Kumar, Alice Saito, Hershraj Niranjani, Rayan Yessou, Phan Xuan Tan</div>
<div class="meta-line">First: 2026-01-31T14:41:43+00:00 · Latest: 2026-01-31T14:41:43+00:00</div>
<div class="meta-line">Comments: 23 pages, 4 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.00755v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.00755v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Constitutional AI has focused on single-model alignment using fixed principles. However, multi-agent systems create novel alignment challenges through emergent social dynamics. We present Constitutional Evolution, a framework for automatically discovering behavioral norms in multi-agent LLM systems. Using a grid-world simulation with survival pressure, we study the tension between individual and collective welfare, quantified via a Societal Stability Score S in [0,1] that combines productivity, survival, and conflict metrics. Adversarial constitutions lead to societal collapse (S= 0), while vague prosocial principles (&quot;be helpful, harmless, honest&quot;) produce inconsistent coordination (S = 0.249). Even constitutions designed by Claude 4.5 Opus with explicit knowledge of the objective achieve only moderate performance (S= 0.332). Using LLM-driven genetic programming with multi-island evolution, we evolve constitutions maximizing social welfare without explicit guidance toward cooperation. The evolved constitution C* achieves S = 0.556 +/- 0.008 (123% higher than human-designed baselines, N = 10), eliminates conflict, and discovers that minimizing communication (0.9% vs 62.2% social actions) outperforms verbose coordination. Our interpretable rules demonstrate that cooperative norms can be discovered rather than prescribed.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Constitutional AI has focused on single-model alignment using fixed principles.</div>
</details>
</div>
<div class="card">
<div class="title">HumanStudy-Bench: Towards AI Agent Design for Participant Simulation</div>
<div class="meta-line">Authors: Xuan Liu, Haoyang Shang, Zizhang Liu, Xinyan Liu, Yunze Xiao, Yiwen Tu, Haojian Jin</div>
<div class="meta-line">First: 2026-01-31T12:07:42+00:00 · Latest: 2026-01-31T12:07:42+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2602.00685v1">Abs</a> · <a href="https://arxiv.org/pdf/2602.00685v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models (LLMs) are increasingly used as simulated participants in social science experiments, but their behavior is often unstable and highly sensitive to design choices. Prior evaluations frequently conflate base-model capabilities with experimental instantiation, obscuring whether outcomes reflect the model itself or the agent setup. We instead frame participant simulation as an agent-design problem over full experimental protocols, where an agent is defined by a base model and a specification (e.g., participant attributes) that encodes behavioral assumptions. We introduce HUMANSTUDY-BENCH, a benchmark and execution engine that orchestrates LLM-based agents to reconstruct published human-subject experiments via a Filter--Extract--Execute--Evaluate pipeline, replaying trial sequences and running the original analysis pipeline in a shared runtime that preserves the original statistical procedures end to end. To evaluate fidelity at the level of scientific inference, we propose new metrics to quantify how much human and agent behaviors agree. We instantiate 12 foundational studies as an initial suite in this dynamic benchmark, spanning individual cognition, strategic interaction, and social psychology, and covering more than 6,000 trials with human samples ranging from tens to over 2,100 participants.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large language models (LLMs) are increasingly used as simulated participants in social science experiments, but their behavior is often unstable and highly sensitive to design choices.</div>
</details>
</div>
<div class="card">
<div class="title">Reflecting with Two Voices: A Co-Adaptive Dual-Strategy Framework for LLM-Based Agent Decision Making</div>
<div class="meta-line">Authors: Wentao Zhang, Qunbo Wang, BoXuan Zhao, Tao Zhang, Junsheng Wu, Hongping Gan, Ling Dai, Shizhuang Deng, Shuntong Sun, Yang Liu</div>
<div class="meta-line">First: 2025-12-09T08:44:59+00:00 · Latest: 2026-01-31T03:46:11+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.08366v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.08366v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language model (LLM) agents often rely on external demonstrations or retrieval-augmented planning, leading to brittleness, poor generalization, and high computational overhead. Inspired by human problem-solving, we propose DuSAR (Dual-Strategy Agent with Reflecting) -- a demonstration-free framework that enables a single frozen LLM to perform co-adaptive reasoning via two complementary strategies: a high-level holistic plan and a context-grounded local policy. These strategies interact through a lightweight reflection mechanism, where the agent continuously assesses progress via a Strategy Fitness Score and dynamically revises its global plan when stuck or refines it upon meaningful advancement, mimicking human metacognitive behavior. On both simulated household (ALFWorld) and real-world web (Mind2Web) environments, DuSAR achieves state-of-the-art performance using only open-source LLMs, substantially outperforming all prior methods without any demonstrations or fine-tuning. Remarkably, it also reduces per-step token consumption by a large margin while maintaining strong task success. Ablation studies confirm the necessity of dual-strategy coordination. Moreover, optional integration of expert demonstrations further boosts performance, highlighting DuSAR&#x27;s flexibility and compatibility with external knowledge.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>双声反思：基于LLM的智能体决策协同自适应双策略框架</div>
<div class="mono" style="margin-top:8px">大型语言模型（LLM）智能体常依赖外部演示或检索增强规划，导致脆弱性、泛化能力差及高计算开销。受人类问题解决机制启发，我们提出DuSAR（双策略反思智能体）——一种无需演示的框架，使单个冻结LLM能通过两种互补策略执行协同自适应推理：高层整体规划与情境驱动的局部策略。这些策略通过轻量级反思机制交互：智能体持续通过策略适应度评分（SFS）评估进展，在受阻时动态修正全局计划，或在取得实质进展时优化策略，模拟人类元认知行为。在模拟家居（ALFWorld）和真实网页（Mind2Web）环境中，DuSAR仅使用开源LLM即达到领先水平，显著超越所有现有方法且无需任何演示或微调。值得注意的是，它在保持高任务成功率的同时大幅降低单步token消耗。消融研究证实双策略协同的必要性。此外，选择性集成专家演示可进一步提升性能，彰显DuSAR的灵活性与外部知识兼容性。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large language model (LLM) agents often rely on external demonstrations or retrieval-augmented planning, leading to brittleness, poor generalization, and high computational overhead.</div>
</details>
</div>
<div class="card">
<div class="title">AgentAuditor: Human-Level Safety and Security Evaluation for LLM Agents</div>
<div class="meta-line">Authors: Hanjun Luo, Shenyu Dai, Chiming Ni, Xinfeng Li, Guibin Zhang, Kun Wang, Tongliang Liu, Hanan Salam</div>
<div class="meta-line">Venue: NeurIPS 2025</div>
<div class="meta-line">First: 2025-05-31T17:10:23+00:00 · Latest: 2026-01-31T00:21:14+00:00</div>
<div class="meta-line">Comments: This paper is accepted by 39th Conference on Neural Information Processing Systems (NeurIPS 2025)</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.00641v3">Abs</a> · <a href="https://arxiv.org/pdf/2506.00641v3">PDF</a> · <a href="https://github.com/Astarojth/AgentAuditor">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Despite the rapid advancement of LLM-based agents, the reliable evaluation of their safety and security remains a significant challenge. Existing rule-based or LLM-based evaluators often miss dangers in agents&#x27; step-by-step actions, overlook subtle meanings, fail to see how small issues compound, and get confused by unclear safety or security rules. To overcome this evaluation crisis, we introduce AgentAuditor, a universal, training-free, memory-augmented reasoning framework that empowers LLM evaluators to emulate human expert evaluators. AgentAuditor constructs an experiential memory by having an LLM adaptively extract structured semantic features (e.g., scenario, risk, behavior) and generate associated chain-of-thought reasoning traces for past interactions. A multi-stage, context-aware retrieval-augmented generation process then dynamically retrieves the most relevant reasoning experiences to guide the LLM evaluator&#x27;s assessment of new cases. Moreover, we developed ASSEBench, the first benchmark designed to check how well LLM-based evaluators can spot both safety risks and security threats. ASSEBench comprises 2293 meticulously annotated interaction records, covering 15 risk types across 29 application scenarios. A key feature of ASSEBench is its nuanced approach to ambiguous risk situations, employing &quot;Strict&quot; and &quot;Lenient&quot; judgment standards. Experiments demonstrate that AgentAuditor not only consistently improves the evaluation performance of LLMs across all benchmarks but also sets a new state-of-the-art in LLM-as-a-judge for agent safety and security, achieving human-level accuracy. Our work is openly accessible at https://github.com/Astarojth/AgentAuditor.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Despite the rapid advancement of LLM-based agents, the reliable evaluation of their safety and security remains a significant challenge.</div>
</details>
</div>
<div class="card">
<div class="title">Large Language Model Agent for User-friendly Chemical Process Simulations</div>
<div class="meta-line">Authors: Jingkang Liang, Niklas Groll, Gürkan Sin</div>
<div class="meta-line">First: 2026-01-15T12:18:45+00:00 · Latest: 2026-01-30T14:45:08+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.11650v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.11650v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Modern process simulators enable detailed process design, simulation, and optimization; however, constructing and interpreting simulations is time-consuming and requires expert knowledge. This limits early exploration by inexperienced users. To address this, a large language model (LLM) agent is integrated with AVEVA Process Simulation (APS) via Model Context Protocol (MCP), allowing natural language interaction with rigorous process simulations. An MCP server toolset enables the LLM to communicate programmatically with APS using Python, allowing it to execute complex simulation tasks from plain-language instructions. Two water-methanol separation case studies assess the framework across different task complexities and interaction modes. The first shows the agent autonomously analyzing flowsheets, finding improvement opportunities, and iteratively optimizing, extracting data, and presenting results clearly. The framework benefits both educational purposes, by translating technical concepts and demonstrating workflows, and experienced practitioners by automating data extraction, speeding routine tasks, and supporting brainstorming. The second case study assesses autonomous flowsheet synthesis through both a step-by-step dialogue and a single prompt, demonstrating its potential for novices and experts alike. The step-by-step mode gives reliable, guided construction suitable for educational contexts; the single-prompt mode constructs fast baseline flowsheets for later refinement. While current limitations such as oversimplification, calculation errors, and technical hiccups mean expert oversight is still needed, the framework&#x27;s capabilities in analysis, optimization, and guided construction suggest LLM-based agents can become valuable collaborators.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Modern process simulators enable detailed process design, simulation, and optimization; however, constructing and interpreting simulations is time-consuming and requires expert knowledge.</div>
</details>
</div>
<div class="card">
<div class="title">FlexLoRA: Entropy-Guided Flexible Low-Rank Adaptation</div>
<div class="meta-line">Authors: Muqing Liu, Chongjie Si, Yuheng Jia</div>
<div class="meta-line">Venue: ICLR</div>
<div class="meta-line">First: 2026-01-30T12:25:47+00:00 · Latest: 2026-01-30T12:25:47+00:00</div>
<div class="meta-line">Comments: 2026 ICLR. Codes in https://github.com/Chongjie-Si/Subspace-Tuning</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22905v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22905v1">PDF</a> · <a href="https://github.com/Chongjie-Si/Subspace-Tuning">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large pre-trained models achieve remarkable success across diverse domains, yet fully fine-tuning incurs prohibitive computational and memory costs. Parameter-efficient fine-tuning (PEFT) has thus become a mainstream paradigm. Among them, Low-Rank Adaptation (LoRA) introduces trainable low-rank matrices and shows strong performance, nevertheless, its fixed-rank design limits flexibility. Dynamic rank allocation methods mitigate this issue by pruning redundant directions; however, they often rely on heuristic, element-level metrics that globally sort rank directions without matrix-wise distinction, and they lack mechanisms to expand capacity in layers requiring additional adaptation. To overcome these limitations, we propose FlexLoRA, an entropy-guided flexible low-rank adaptation framework that (i) evaluates matrix importance via spectral energy entropy, (ii) supports rank pruning and expansion under a global budget, and (iii) employs zero-impact initialization for newly added singular directions to ensure stability. By addressing granularity, flexibility, and stability limitations, FlexLoRA provides a more principled solution for PEFT. Extensive experiments show that FlexLoRA consistently outperforms state-of-the-art baselines across benchmarks. Codes are available at https://github.com/Chongjie-Si/Subspace-Tuning.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">To address the prohibitive computational costs of fully fine-tuning large pre-trained models and the inflexibility of fixed-rank Low-Rank Adaptation (LoRA), which limits adaptability, FlexLoRA introduces an entropy-guided framework for dynamic rank allocation. The method evaluates matrix importance using spectral energy entropy, supports both rank pruning and expansion under a global budget, and employs zero-impact initialization for new singular directions to ensure stability. Experimental results demonstrate that FlexLoRA consistently outperforms state-of-the-art baselines across multiple benchmarks.</div>
<div class="mono" style="margin-top:8px">为解决完全微调大型预训练模型的高昂计算成本以及固定秩的低秩自适应（LoRA）方法灵活性不足的问题，FlexLoRA提出了一种基于熵引导的动态秩分配框架。该方法利用谱能量熵评估矩阵重要性，支持在全局预算下进行秩的剪枝和扩展，并为新增奇异方向采用零影响初始化以确保稳定性。实验结果表明，FlexLoRA在多个基准测试中均优于现有最先进方法。</div>
</details>
</div>
<div class="card">
<div class="title">Breaking the Blocks: Continuous Low-Rank Decomposed Scaling for Unified LLM Quantization and Adaptation</div>
<div class="meta-line">Authors: Pingzhi Tang, Ruijie Zhou, Fanxu Meng, Wenjie Pei, Muhan Zhang</div>
<div class="meta-line">First: 2026-01-30T08:46:02+00:00 · Latest: 2026-01-30T08:46:02+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22716v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22716v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Current quantization methods for LLMs predominantly rely on block-wise structures to maintain efficiency, often at the cost of representational flexibility. In this work, we demonstrate that element-wise quantization can be made as efficient as block-wise scaling while providing strictly superior expressive power by modeling the scaling manifold as continuous low-rank matrices ($S = BA$). We propose Low-Rank Decomposed Scaling (LoRDS), a unified framework that rethinks quantization granularity through this low-rank decomposition. By &quot;breaking the blocks&quot; of spatial constraints, LoRDS establishes a seamless efficiency lifecycle: it provides high-fidelity PTQ initialization refined via iterative optimization, enables joint QAT of weights and scaling factors, and facilitates high-rank multiplicative PEFT adaptation. Unlike additive PEFT approaches such as QLoRA, LoRDS enables high-rank weight updates within a low-rank budget while incurring no additional inference overhead. Supported by highly optimized Triton kernels, LoRDS consistently outperforms state-of-the-art baselines across various model families in both quantization and downstream fine-tuning tasks. Notably, on Llama3-8B, our method achieves up to a 27.0% accuracy improvement at 3 bits over NormalFloat quantization and delivers a 1.5x inference speedup on NVIDIA RTX 4090 while enhancing PEFT performance by 9.6% on downstream tasks over 4bit QLoRA, offering a robust and integrated solution for unified compression and adaptation of LLMs.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Current quantization methods for LLMs predominantly rely on block-wise structures to maintain efficiency, often at the cost of representational flexibility.</div>
</details>
</div>
<div class="card">
<div class="title">PEFT-MuTS: A Multivariate Parameter-Efficient Fine-Tuning Framework for Remaining Useful Life Prediction based on Cross-domain Time Series Representation Model</div>
<div class="meta-line">Authors: En Fu, Yanyan Hu, Changhua Hu, Zengwang Jin, Kaixiang Peng</div>
<div class="meta-line">First: 2026-01-30T06:46:57+00:00 · Latest: 2026-01-30T06:46:57+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.22631v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.22631v1">PDF</a> · <a href="https://github.com/fuen1590/PEFT-MuTS">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The application of data-driven remaining useful life (RUL) prediction has long been constrained by the availability of large amount of degradation data. Mainstream solutions such as domain adaptation and meta-learning still rely on large amounts of historical degradation data from equipment that is identical or similar to the target, which imposes significant limitations in practical applications. This study investigates PEFT-MuTS, a Parameter-Efficient Fine-Tuning framework for few-shot RUL prediction, built on cross-domain pre-trained time-series representation models. Contrary to the widely held view that knowledge transfer in RUL prediction can only occur within similar devices, we demonstrate that substantial benefits can be achieved through pre-training process with large-scale cross-domain time series datasets. A independent feature tuning network and a meta-variable-based low rank multivariate fusion mechanism are developed to enable the pre-trained univariate time-series representation backbone model to fully exploit the multivariate relationships in degradation data for downstream RUL prediction task. Additionally, we introduce a zero-initialized regressor that stabilizes the fine-tuning process under few-shot conditions. Experiments on aero-engine and industrial bearing datasets demonstrate that our method can achieve effective RUL prediction even when less than 1\% of samples of target equipment are used. Meanwhile, it substantially outperforms conventional supervised and few-shot approaches while markedly reducing the data required to achieve high predictive accuracy. Our code is available at https://github.com/fuen1590/PEFT-MuTS.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The application of data-driven remaining useful life (RUL) prediction has long been constrained by the availability of large amount of degradation data.</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260202_0404.html">20260202_0404</a>
<a href="archive/20260201_1746.html">20260201_1746</a>
<a href="archive/20260201_1152.html">20260201_1152</a>
<a href="archive/20260201_0333.html">20260201_0333</a>
<a href="archive/20260131_0345.html">20260131_0345</a>
<a href="archive/20260130_0341.html">20260130_0341</a>
<a href="archive/20260129_0344.html">20260129_0344</a>
<a href="archive/20260128_0341.html">20260128_0341</a>
<a href="archive/20260127_0338.html">20260127_0338</a>
<a href="archive/20260126_0330.html">20260126_0330</a>
<a href="archive/20260125_0329.html">20260125_0329</a>
<a href="archive/20260124_0337.html">20260124_0337</a>
<a href="archive/20260123_0337.html">20260123_0337</a>
<a href="archive/20260122_0343.html">20260122_0343</a>
<a href="archive/20260121_0424.html">20260121_0424</a>
<a href="archive/20260119_0329.html">20260119_0329</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a>
<a href="archive/20251008_0343.html">20251008_0343</a>
<a href="archive/20251007_0353.html">20251007_0353</a>
<a href="archive/20251006_0325.html">20251006_0325</a>
<a href="archive/20251005_0350.html">20251005_0350</a>
<a href="archive/20251004_0352.html">20251004_0352</a>
<a href="archive/20251003_0352.html">20251003_0352</a>
<a href="archive/20251002_0356.html">20251002_0356</a>
<a href="archive/20251001_0321.html">20251001_0321</a>
<a href="archive/20250925_0335.html">20250925_0335</a>
<a href="archive/20250924_0350.html">20250924_0350</a>
<a href="archive/20250923_0348.html">20250923_0348</a>
<a href="archive/20250922_0346.html">20250922_0346</a>
<a href="archive/20250921_0345.html">20250921_0345</a>
<a href="archive/20250920_0342.html">20250920_0342</a>
<a href="archive/20250919_0346.html">20250919_0346</a>
<a href="archive/20250918_0342.html">20250918_0342</a>
<a href="archive/20250917_0336.html">20250917_0336</a>
<a href="archive/20250916_0333.html">20250916_0333</a>
<a href="archive/20250915_0333.html">20250915_0333</a>
<a href="archive/20250914_0328.html">20250914_0328</a>
<a href="archive/20250913_0322.html">20250913_0322</a>
<a href="archive/20250912_0335.html">20250912_0335</a>
<a href="archive/20250911_0337.html">20250911_0337</a>
<a href="archive/20250910_0338.html">20250910_0338</a>
<a href="archive/20250909_0341.html">20250909_0341</a>
<a href="archive/20250908_0342.html">20250908_0342</a>
<a href="archive/20250907_0333.html">20250907_0333</a>
<a href="archive/20250906_0350.html">20250906_0350</a>
<a href="archive/20250905_0319.html">20250905_0319</a>
<a href="archive/20250904_0323.html">20250904_0323</a>
<a href="archive/20250903_0355.html">20250903_0355</a>
<a href="archive/20250902_0325.html">20250902_0325</a>
<a href="archive/20250901_0355.html">20250901_0355</a>
<a href="archive/20250831_0355.html">20250831_0355</a>
<a href="archive/20250830_0356.html">20250830_0356</a>
<a href="archive/20250829_0355.html">20250829_0355</a>
<a href="archive/20250828_0333.html">20250828_0333</a>
<a href="archive/20250827_1654.html">20250827_1654</a>
<a href="archive/20250827_1602.html">20250827_1602</a>
<a href="archive/20250827_1557.html">20250827_1557</a>
<a href="archive/20250827_0320.html">20250827_0320</a>
<a href="archive/20250826_0320.html">20250826_0320</a>
<a href="archive/20250825_1752.html">20250825_1752</a>
<a href="archive/20250825_1709.html">20250825_1709</a>
<a href="archive/20250825_1652.html">20250825_1652</a>
<a href="archive/20250825_1647.html">20250825_1647</a>
<a href="archive/20250825_1645.html">20250825_1645</a>
<a href="archive/20250825_1631.html">20250825_1631</a>
<a href="archive/20250825_1606.html">20250825_1606</a>
<a href="archive/20250825_1559.html">20250825_1559</a>
<a href="archive/20250825_1558.html">20250825_1558</a>
<a href="archive/20250825_1556.html">20250825_1556</a>
<a href="archive/20250825_1531.html">20250825_1531</a>
<a href="archive/20250825_1525.html">20250825_1525</a>
<a href="archive/20250825_1516.html">20250825_1516</a>
<a href="archive/20250825_1450.html">20250825_1450</a>
<a href="archive/20250825_1444.html">20250825_1444</a>
<a href="archive/20250825_1438.html">20250825_1438</a>
<a href="archive/20250825_1414.html">20250825_1414</a>
<a href="archive/20250825_1413.html">20250825_1413</a>
<a href="archive/20250825_1410.html">20250825_1410</a>
<a href="archive/20250825_1408.html">20250825_1408</a>
<a href="archive/20250825_1405.html">20250825_1405</a>
<a href="archive/20250825_1401.html">20250825_1401</a>
<a href="archive/20250825_1355.html">20250825_1355</a>
<a href="archive/20250825_1347.html">20250825_1347</a>
<a href="archive/20250825_1345.html">20250825_1345</a>
<a href="archive/20250825_1344.html">20250825_1344</a>
<a href="archive/20250825_1343.html">20250825_1343</a>
<a href="archive/20250825_1340.html">20250825_1340</a>
<a href="archive/20250825_1339.html">20250825_1339</a>
<a href="archive/20250825_1333.html">20250825_1333</a>
<a href="archive/20250825_1323.html">20250825_1323</a>
<a href="archive/20250825_1317.html">20250825_1317</a>
<a href="archive/20250825_1243.html">20250825_1243</a>
<a href="archive/20250824_0342.html">20250824_0342</a>
<a href="archive/20250823_0343.html">20250823_0343</a>
<a href="archive/20250823_0142.html">20250823_0142</a>
<a href="archive/20250822_2331.html">20250822_2331</a>
<a href="archive/20250822_2308.html">20250822_2308</a>
<a href="archive/20250822_2258.html">20250822_2258</a>
<a href="archive/20250822_2241.html">20250822_2241</a>
<a href="archive/20250822_2228.html">20250822_2228</a>
<a href="archive/20250822_2206.html">20250822_2206</a>
<a href="archive/20250822_2147.html">20250822_2147</a>
<a href="archive/20250822_2111.html">20250822_2111</a>
<a href="archive/20250822_1259.html">20250822_1259</a>
<a href="archive/20250822_1233.html">20250822_1233</a>
<a href="archive/20250822_1229.html">20250822_1229</a>
<a href="archive/20250822_1223.html">20250822_1223</a>
<a href="archive/20250822_1210.html">20250822_1210</a>
<a href="archive/20250822_1201.html">20250822_1201</a>
<a href="archive/20250822_1111.html">20250822_1111</a>
<a href="archive/20250822_1058.html">20250822_1058</a>
<a href="archive/20250822_1052.html">20250822_1052</a>
<a href="archive/20250822_1045.html">20250822_1045</a>
<a href="archive/20250822_0657.html">20250822_0657</a>
<a href="archive/20250822_0553.html">20250822_0553</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
