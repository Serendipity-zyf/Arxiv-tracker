<!doctype html>
<html><head><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>arXiv 论文速递</title><style>
:root {
  --bg:#f8fafc; --card:#ffffff; --text:#0f172a; --muted:#667085; --border:#e5e7eb; --acc:#2563eb;
}
:root[data-theme="dark"] {
  --bg:#0b0f17; --card:#111827; --text:#e5e7eb; --muted:#9ca3af; --border:#1f2937; --acc:#2563eb;
}
*{box-sizing:border-box} body{margin:0;background:var(--bg);color:var(--text);
  font-family:ui-sans-serif,system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial;line-height:1.6;}
.container{max-width:900px;margin:0 auto;padding:18px;}
.header{display:flex;gap:10px;justify-content:space-between;align-items:center;margin:8px 0 16px;flex-wrap:wrap}
h1{font-size:22px;margin:0}
.badge{font-size:12px;color:#111827;background:var(--acc);padding:2px 8px;border-radius:999px}
.card{background:var(--card);border:1px solid var(--border);border-radius:16px;padding:16px 18px;margin:14px 0;box-shadow:0 1px 2px rgba(0,0,0,.04)}
.title{font-weight:700;margin:0 0 6px 0;font-size:18px}
.meta-line{color:var(--muted);font-size:13px;margin:2px 0}
.links a{color:var(--acc);text-decoration:none;margin-right:12px}
.detail{margin-top:10px;background:rgba(2,6,23,.03);border:1px solid var(--border);border-radius:10px;padding:8px 10px}
summary{cursor:pointer;color:var(--acc)}
.mono{white-space:pre-wrap;background:rgba(2,6,23,.03);border:1px solid var(--border);padding:10px;border-radius:10px}
.row{display:grid;grid-template-columns:1fr;gap:12px}
@media (min-width: 860px) {
  .row-2{grid-template-columns:1fr 1fr}
}
.footer{color:var(--muted);font-size:13px;margin:20px 0 10px}
.hr{height:1px;background:var(--border);margin:14px 0}
.history-list a{display:block;color:var(--acc);text-decoration:none;margin:4px 0}
.controls{display:flex;gap:8px;align-items:center}
.btn{border:1px solid var(--border);background:var(--card);padding:6px 10px;border-radius:10px;cursor:pointer;color:var(--text)}
.btn:hover{border-color:var(--acc)}
</style>
<script>
(function() {
  const root = document.documentElement;
  function apply(t) {
    if (t==='dark') root.setAttribute('data-theme','dark');
    else if (t==='light') root.removeAttribute('data-theme');
    else {
      if (window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches)
        root.setAttribute('data-theme','dark');
      else root.removeAttribute('data-theme');
    }
  }
  let t = localStorage.getItem('theme') || 'light';
  if (!['light','dark','auto'].includes(t)) t='light';
  apply(t);
  window.__toggleTheme = function() {
    let cur = localStorage.getItem('theme') || 'light';
    if (cur==='light') cur='dark';
    else if (cur==='dark') cur='auto';
    else cur='light';
    localStorage.setItem('theme', cur);
    apply(cur);
    const el=document.getElementById('theme-label');
    if(el) el.textContent = cur.toUpperCase();
  }
  window.__expandAll = function(open) {
    document.querySelectorAll('details').forEach(d => d.open = !!open);
  }
})();
</script>
</head>
<body>
  <div class="container">
    <div class="header">
      <h1>arXiv 论文速递</h1>
      <div style="display:flex;gap:10px;align-items:center">
        
<div class="controls">
  <button class="btn" onclick="__toggleTheme()">Theme: <span id="theme-label" style="margin-left:6px">AUTO</span></button>
  <button class="btn" onclick="__expandAll(true)">Expand All</button>
  <button class="btn" onclick="__expandAll(false)">Collapse All</button>
</div>

        <span class="badge">2026-02-02 04:04</span>
      </div>
    </div>
    <div class="hr"></div>
    <div>Snapshot: 20260202_0404</div>
    <div class="row"><div class="card">
<div class="title">TS-PEFT: Unveiling Token-Level Redundancy in Parameter-Efficient Fine-Tuning</div>
<div class="meta-line">Authors: Dabiao Ma, Ziming Dai, Zhimin Xin, Shu Wang, Jian Yang, Haojun Fei</div>
<div class="meta-line">First: 2025-11-20T08:41:20+00:00 · Latest: 2026-01-29T12:19:42+00:00</div>
<div class="meta-line">Comments: 11 pages, 3 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.16147v3">Abs</a> · <a href="https://arxiv.org/pdf/2511.16147v3">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Current Parameter-Efficient Fine-Tuning (PEFT) methods typically operate under an implicit assumption: Once a target module is selected, every token passing through it contributes equally to the downstream task and requires a parameter update. In this paper, we challenge this convention by revealing a pervasive token-level redundancy in the fine-tuning of large models (LMs). We propose TS-PEFT, a theoretical framework utilizing proximal optimization that acts as a dynamic probe to identify token-level redundancy during the fine-tuning process. Extensive experiments demonstrate that indiscriminately updating all tokens is not only computationally superfluous but often introduces optimization noise. Surprisingly, by discarding 30%-70% of token updates, TS-PEFT consistently matches or exceeds the performance of dense baselines such as LoRA, DoRA. Our in-depth analysis shows that the learned token-level sparsity is a superior indicator of module importance compared to traditional weight criteria, providing a novel data-driven perspective on the intrinsic adaptation mechanism of LMs.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Current Parameter-Efficient Fine-Tuning (PEFT) methods typically operate under an implicit assumption: Once a target module is selected, every token passing through it contributes equally to the downstream task and requires a parameter update.</div>
</details>
</div>
<div class="card">
<div class="title">ShardMemo: Masked MoE Routing for Sharded Agentic LLM Memory</div>
<div class="meta-line">Authors: Yang Zhao, Chengxiao Dai, Yue Xiu, Mengying Kou, Yuliang Zheng, Dusit Niyato</div>
<div class="meta-line">First: 2026-01-29T11:01:34+00:00 · Latest: 2026-01-29T11:01:34+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.21545v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.21545v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Agentic large language model (LLM) systems rely on external memory for long-horizon state and concurrent multi-agent execution, but centralized indexes and heuristic partitions become bottlenecks as memory volume and parallel access grow. We present ShardMemo, a budgeted tiered memory service with Tier A per-agent working state, Tier B sharded evidence with shard-local approximate nearest neighbor (ANN) indexes, and Tier C, a versioned skill library. Tier B enforces scope-before-routing: structured eligibility constraints mask ineligible shards before routing or ANN search. We cast shard probing as masked mixture-of-experts (MoE) routing over eligible shards, probing up to $B_{\mathrm{probe}}$ shards via Top-$B_{\mathrm{probe}}$ or adaptive Top-$P$, and use cost-aware gating over profile/observation/session shard families; the router is trained from evidence-to-shard supervision. On LoCoMo, ShardMemo improves over the strongest baseline (GAM) by +5.11 to +6.82 F1 across question categories. Under a fixed-budget routing setting ($B_{\mathrm{probe}}=3$), ShardMemo improves over cosine-to-prototype shard routing by +6.87 F1 while reducing retrieval work (VecScan 521-&gt;414, -20.5%) and p95 latency (95-&gt;76 ms). On long-context HotpotQA, ShardMemo achieves 63.41/61.88/57.95 F1 at 56K/224K/448K tokens. On ToolBench, Tier C reaches 0.97 Precision@3 and 1.94 StepRed (+10.2% and +7.2% over embedding-similarity retrieval).</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Agentic large language model (LLM) systems rely on external memory for long-horizon state and concurrent multi-agent execution, but centralized indexes and heuristic partitions become bottlenecks as memory volume and parallel access grow.</div>
</details>
</div>
<div class="card">
<div class="title">Should I Have Expressed a Different Intent? Counterfactual Generation for LLM-Based Autonomous Control</div>
<div class="meta-line">Authors: Amirmohammad Farzaneh, Salvatore D&#x27;Oro, Osvaldo Simeone</div>
<div class="meta-line">First: 2026-01-27T22:18:57+00:00 · Latest: 2026-01-29T06:09:51+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20090v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.20090v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language model (LLM)-powered agents can translate high-level user intents into plans and actions in an environment. Yet after observing an outcome, users may wonder: What if I had phrased my intent differently? We introduce a framework that enables such counterfactual reasoning in agentic LLM-driven control scenarios, while providing formal reliability guarantees. Our approach models the closed-loop interaction between a user, an LLM-based agent, and an environment as a structural causal model (SCM), and leverages test-time scaling to generate multiple candidate counterfactual outcomes via probabilistic abduction. Through an offline calibration phase, the proposed conformal counterfactual generation (CCG) yields sets of counterfactual outcomes that are guaranteed to contain the true counterfactual outcome with high probability. We showcase the performance of CCG on a wireless network control use case, demonstrating significant advantages compared to naive re-execution baselines.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>我是否应表达不同意图？基于大语言模型的自主控制反事实生成</div>
<div class="mono" style="margin-top:8px">大语言模型（LLM）驱动的智能体可将高级用户意图转化为环境中的规划与行动。然而在观察结果后，用户可能思考：若当初采用不同表述会如何？我们提出一个框架，在基于LLM的自主控制场景中实现此类反事实推理，并提供形式化可靠性保证。该方法通过结构因果模型（SCM）建模用户、LLM智能体与环境间的闭环交互，利用测试时缩放技术通过概率溯因生成多重候选反事实结果。经离线校准阶段，所提出的保形反事实生成（CCG）技术可确保以高概率包含真实反事实结果。我们在无线网络控制案例中验证CCG性能，较朴素重执行基线展现出显著优势。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large language model (LLM)-powered agents can translate high-level user intents into plans and actions in an environment.</div>
</details>
</div>
<div class="card">
<div class="title">From Specialist to Generalist: Unlocking SAM&#x27;s Learning Potential on Unlabeled Medical Images</div>
<div class="meta-line">Authors: Vi Vu, Thanh-Huy Nguyen, Tien-Thinh Nguyen, Ba-Thinh Lam, Hoang-Thien Nguyen, Tianyang Wang, Xingjian Li, Min Xu</div>
<div class="meta-line">Venue: ISBI 2026</div>
<div class="meta-line">First: 2026-01-25T18:13:48+00:00 · Latest: 2026-01-28T18:55:46+00:00</div>
<div class="meta-line">Comments: Accepted to ISBI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.17934v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.17934v2">PDF</a> · <a href="https://github.com/vnlvi2k3/SC-SAM">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Foundation models like the Segment Anything Model (SAM) show strong generalization, yet adapting them to medical images remains difficult due to domain shift, scarce labels, and the inability of Parameter-Efficient Fine-Tuning (PEFT) to exploit unlabeled data. While conventional models like U-Net excel in semi-supervised medical learning, their potential to assist a PEFT SAM has been largely overlooked. We introduce SC-SAM, a specialist-generalist framework where U-Net provides point-based prompts and pseudo-labels to guide SAM&#x27;s adaptation, while SAM serves as a powerful generalist supervisor to regularize U-Net. This reciprocal guidance forms a bidirectional co-training loop that allows both models to effectively exploit the unlabeled data. Across prostate MRI and polyp segmentation benchmarks, our method achieves state-of-the-art results, outperforming other existing semi-supervised SAM variants and even medical foundation models like MedSAM, highlighting the value of specialist-generalist cooperation for label-efficient medical image segmentation. Our code is available at https://github.com/vnlvi2k3/SC-SAM.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Foundation models like the Segment Anything Model (SAM) show strong generalization, yet adapting them to medical images remains difficult due to domain shift, scarce labels, and the inability of Parameter-Efficient Fine-Tuning (PEFT) to exploit unlabeled data.</div>
</details>
</div>
<div class="card">
<div class="title">Investigating the Development of Task-Oriented Communication in Vision-Language Models</div>
<div class="meta-line">Authors: Boaz Carmeli, Orr Paradise, Shafi Goldwasser, Yonatan Belinkov, Ron Meir</div>
<div class="meta-line">First: 2026-01-28T14:28:31+00:00 · Latest: 2026-01-28T14:28:31+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20641v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20641v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">We investigate whether \emph{LLM-based agents} can develop task-oriented communication protocols that differ from standard natural language in collaborative reasoning tasks. Our focus is on two core properties such task-oriented protocols may exhibit: Efficiency -- conveying task-relevant information more concisely than natural language, and Covertness -- becoming difficult for external observers to interpret, raising concerns about transparency and control. To investigate these aspects, we use a referential-game framework in which vision-language model (VLM) agents communicate, providing a controlled, measurable setting for evaluating language variants. Experiments show that VLMs can develop effective, task-adapted communication patterns. At the same time, they can develop covert protocols that are difficult for humans and external agents to interpret. We also observe spontaneous coordination between similar models without explicitly shared protocols. These findings highlight both the potential and the risks of task-oriented communication, and position referential games as a valuable testbed for future work in this area.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>探究视觉语言模型中任务导向型通信的发展</div>
<div class="mono" style="margin-top:8px">本研究探讨基于大语言模型（LLM）的智能体能否在协作推理任务中发展出不同于标准自然语言的任务导向型通信协议。我们重点关注此类协议可能具备的两大核心特性：高效性——比自然语言更简洁地传递任务相关信息；隐蔽性——使外部观察者难以解读，引发透明度与控制力方面的担忧。通过视觉语言模型（VLM）智能体在指称博弈框架中的通信实验，我们构建了可量化评估语言变体的受控环境。实验表明：VLM能发展出高效且适应任务的通信模式，同时形成人类与外部智能体难以解读的隐蔽协议。我们还观察到相似模型间无需显式共享协议即可实现自发协调。这些发现既揭示了任务导向型通信的潜力与风险，也确立了指称博弈作为该领域未来研究的有效实验平台。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">We investigate whether \emph{LLM-based agents} can develop task-oriented communication protocols that differ from standard natural language in collaborative reasoning tasks.</div>
</details>
</div>
<div class="card">
<div class="title">Agent Benchmarks Fail Public Sector Requirements</div>
<div class="meta-line">Authors: Jonathan Rystrøm, Chris Schmitz, Karolina Korgul, Jan Batzner, Chris Russell</div>
<div class="meta-line">First: 2026-01-28T13:51:30+00:00 · Latest: 2026-01-28T13:51:30+00:00</div>
<div class="meta-line">Comments: Forthcoming @ IASEAI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20617v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20617v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Deploying Large Language Model-based agents (LLM agents) in the public sector requires assuring that they meet the stringent legal, procedural, and structural requirements of public-sector institutions. Practitioners and researchers often turn to benchmarks for such assessments. However, it remains unclear what criteria benchmarks must meet to ensure they adequately reflect public-sector requirements, or how many existing benchmarks do so. In this paper, we first define such criteria based on a first-principles survey of public administration literature: benchmarks must be \emph{process-based}, \emph{realistic}, \emph{public-sector-specific} and report \emph{metrics} that reflect the unique requirements of the public sector. We analyse more than 1,300 benchmark papers for these criteria using an expert-validated LLM-assisted pipeline. Our results show that no single benchmark meets all of the criteria. Our findings provide a call to action for both researchers to develop public sector-relevant benchmarks and for public-sector officials to apply these criteria when evaluating their own agentic use cases.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Deploying Large Language Model-based agents (LLM agents) in the public sector requires assuring that they meet the stringent legal, procedural, and structural requirements of public-sector institutions.</div>
</details>
</div>
<div class="card">
<div class="title">LLM-AutoDP: Automatic Data Processing via LLM Agents for Model Fine-tuning</div>
<div class="meta-line">Authors: Wei Huang, Anda Cheng, Yinggui Wang, Lei Wang, Tao Wei</div>
<div class="meta-line">First: 2026-01-28T08:37:34+00:00 · Latest: 2026-01-28T08:37:34+00:00</div>
<div class="meta-line">Comments: Accepted by VLDB2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.20375v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.20375v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) can be fine-tuned on domain-specific data to enhance their performance in specialized fields. However, such data often contains numerous low-quality samples, necessitating effective data processing (DP). In practice, DP strategies are typically developed through iterative manual analysis and trial-and-error adjustment. These processes inevitably incur high labor costs and may lead to privacy issues in high-privacy domains like healthcare due to direct human access to sensitive data. Thus, achieving automated data processing without exposing the raw data has become a critical challenge. To address this challenge, we propose LLM-AutoDP, a novel framework that leverages LLMs as agents to automatically generate and optimize data processing strategies. Our method generates multiple candidate strategies and iteratively refines them using feedback signals and comparative evaluations. This iterative in-context learning mechanism enables the agent to converge toward high-quality processing pipelines without requiring direct human intervention or access to the underlying data. To further accelerate strategy search, we introduce three key techniques: Distribution Preserving Sampling, which reduces data volume while maintaining distributional integrity; Processing Target Selection, which uses a binary classifier to identify low-quality samples for focused processing; Cache-and-Reuse Mechanism}, which minimizes redundant computations by reusing prior processing results. Results show that models trained on data processed by our framework achieve over 80% win rates against models trained on unprocessed data. Compared to AutoML baselines based on LLM agents, LLM-AutoDP achieves approximately a 65% win rate. Moreover, our acceleration techniques reduce the total searching time by up to 10 times, demonstrating both effectiveness and efficiency.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large Language Models (LLMs) can be fine-tuned on domain-specific data to enhance their performance in specialized fields.</div>
</details>
</div>
<div class="card">
<div class="title">ComAgent: Multi-LLM based Agentic AI Empowered Intelligent Wireless Networks</div>
<div class="meta-line">Authors: Haoyun Li, Ming Xiao, Kezhi Wang, Robert Schober, Dong In Kim, Yong Liang Guan</div>
<div class="meta-line">First: 2026-01-27T13:43:59+00:00 · Latest: 2026-01-27T13:43:59+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.19607v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.19607v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Emerging 6G networks rely on complex cross-layer optimization, yet manually translating high-level intents into mathematical formulations remains a bottleneck. While Large Language Models (LLMs) offer promise, monolithic approaches often lack sufficient domain grounding, constraint awareness, and verification capabilities. To address this, we present ComAgent, a multi-LLM agentic AI framework. ComAgent employs a closed-loop Perception-Planning-Action-Reflection cycle, coordinating specialized agents for literature search, coding, and scoring to autonomously generate solver-ready formulations and reproducible simulations. By iteratively decomposing problems and self-correcting errors, the framework effectively bridges the gap between user intent and execution. Evaluations demonstrate that ComAgent achieves expert-comparable performance in complex beamforming optimization and outperforms monolithic LLMs across diverse wireless tasks, highlighting its potential for automating design in emerging wireless networks.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>ComAgent：基于多LLM的智能体AI赋能无线网络智能化</div>
<div class="mono" style="margin-top:8px">新兴6G网络依赖复杂的跨层优化，但将高层意图人工转化为数学公式仍是瓶颈。尽管大语言模型（LLM）展现出潜力，单一模型常缺乏足够的领域基础、约束意识和验证能力。为此，我们提出ComAgent——一个多LLM智能体AI框架。该框架采用闭环的感知-规划-行动-反思循环，协调文献检索、编码和评分等专业智能体，自主生成求解器就绪的公式与可复现的仿真。通过迭代分解问题和自我纠错，该框架有效弥合了用户意图与执行间的鸿沟。评估表明，ComAgent在复杂波束赋形优化中达到专家级性能，并在多样化无线任务中超越单一LLM，彰显了其在新兴无线网络自动化设计中的潜力。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Emerging 6G networks rely on complex cross-layer optimization, yet manually translating high-level intents into mathematical formulations remains a bottleneck.</div>
</details>
</div>
<div class="card">
<div class="title">Task-Specific Directions: Definition, Exploration, and Utilization in Parameter Efficient Fine-Tuning</div>
<div class="meta-line">Authors: Chongjie Si, Zhiyi Shi, Shifan Zhang, Xiaokang Yang, Hanspeter Pfister, Wei Shen</div>
<div class="meta-line">First: 2024-09-02T08:10:51+00:00 · Latest: 2026-01-27T06:31:07+00:00</div>
<div class="meta-line">Comments: 2026, TPAMI, Codes in https://github.com/Chongjie-Si/Subspace-Tuning</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2409.01035v5">Abs</a> · <a href="https://arxiv.org/pdf/2409.01035v5">PDF</a> · <a href="https://github.com/Chongjie-Si/Subspace-Tuning">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language models demonstrate impressive performance on downstream tasks, yet they require extensive resource consumption when fully fine-tuning all parameters. To mitigate this, Parameter Efficient Fine-Tuning (PEFT) strategies, such as LoRA, have been developed. In this paper, we delve into the concept of task-specific directions (TSDs), which are critical for transitioning large models from pretrained states to task-specific enhancements in PEFT. We propose a framework to clearly define these directions and explore their properties and practical utilization challenges. We then introduce a novel approach, LoRA-Dash, which aims to maximize the impact of TSDs during the fine-tuning process, thereby enhancing model performance on targeted tasks. Additionally, based on our exploration of TSD, we focus on an important issue in PEFT: the initialization of LoRA. While some works have pointed out the significance of initialization for LoRA&#x27;s performance and proposed various strategies, these methods are often empirical and not task-specific. To address this issue, we propose LoRA-Init. Starting from TSD, we identify the directions that require the most adjustment during fine-tuning for downstream tasks. By initializing the matrices in LoRA with these directions, LoRA-Init significantly enhances LoRA&#x27;s performance. Moreover, we can combine LoRA-Dash and LoRA-Init to create the final version of LoRA based on TSDs, which we refer to as LoRA-TSD. Extensive experiments have conclusively demonstrated the effectiveness of these methods, and in-depth analyses further reveal the underlying mechanisms behind their success.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large language models demonstrate impressive performance on downstream tasks, yet they require extensive resource consumption when fully fine-tuning all parameters.</div>
<div class="mono" style="margin-top:8px">针对大语言模型全参数微调资源消耗高的问题，本研究聚焦参数高效微调（PEFT）中任务特定方向（TSD）的关键作用——即模型从预训练状态转向任务增强的路径。论文提出TSD定义框架，开发了LoRA-Dash以优化微调过程中TSD的影响，并创新LoRA-Init方法：通过识别下游任务最需调整的方向来初始化LoRA矩阵。二者结合形成LoRA-TSD。实验证明该方法显著超越标准LoRA性能，深入分析揭示了其有效性机制。</div>
</details>
</div>
<div class="card">
<div class="title">Agentic Plan Caching: Test-Time Memory for Fast and Cost-Efficient LLM Agents</div>
<div class="meta-line">Authors: Qizheng Zhang, Michael Wornow, Gerry Wan, Kunle Olukotun</div>
<div class="meta-line">Venue: NeurIPS 2025</div>
<div class="meta-line">First: 2025-06-17T04:42:30+00:00 · Latest: 2026-01-26T22:37:12+00:00</div>
<div class="meta-line">Comments: NeurIPS 2025. 27 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2506.14852v2">Abs</a> · <a href="https://arxiv.org/pdf/2506.14852v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">LLM-based agent applications have shown increasingly remarkable capabilities in complex workflows but incur substantial costs and latency due to extensive planning and reasoning requirements. Existing LLM caching techniques (like context caching and semantic caching), primarily designed for serving chatbots, are insufficient for agent applications where outputs depend on external data and environmental contexts. We propose Agentic Plan Caching (APC), a novel test-time memory that extracts, stores, adapts, and reuses structured plan templates from planning stages of agent applications across semantically similar tasks to reduce the cost and latency of serving. Unlike traditional semantic caching, our system extracts plan templates from completed agent executions at test-time, employs keyword extraction to match new requests against cached plans, and utilizes lightweight models to adapt these templates to task-specific plans with contexts. Evaluation across multiple real-world agent applications shows that our system can reduce costs by 50.31% and latency by 27.28% on average while maintaining performance, offering a more efficient solution for serving LLM-based agents that complements existing LLM serving infrastructures.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">LLM-based agent applications have shown increasingly remarkable capabilities in complex workflows but incur substantial costs and latency due to extensive planning and reasoning requirements.</div>
<div class="mono" style="margin-top:8px">基于大语言模型的智能体因复杂的规划推理而产生高昂成本和延迟，且现有面向聊天机器人的缓存技术无法处理外部数据和环境依赖问题。为此，Agentic Plan Caching (APC) 提出从历史执行中提取结构化计划模板，通过关键词匹配新请求，并利用轻量模型适配上下文生成任务专属计划。真实场景实验表明，该方法平均降低50.31%的成本和27.28%的延迟，同时保持性能稳定。</div>
</details>
</div>
<div class="card">
<div class="title">Towards Automated Kernel Generation in the Era of LLMs</div>
<div class="meta-line">Authors: Yang Yu, Peiyu Zang, Chi Hsu Tsai, Haiming Wu, Yixin Shen, Jialing Zhang, Haoyu Wang, Zhiyou Xiao, Jingze Shi, Yuyu Luo, Wentao Zhang, Chunlei Men, Guang Liu, Yonghua Lin</div>
<div class="meta-line">First: 2026-01-22T07:53:52+00:00 · Latest: 2026-01-26T08:47:52+00:00</div>
<div class="meta-line">Comments: 10 pages, 1 figure</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.15727v2">Abs</a> · <a href="https://arxiv.org/pdf/2601.15727v2">PDF</a> · <a href="https://github.com/flagos-ai/awesome-LLM-driven-kernel-generation">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The performance of modern AI systems is fundamentally constrained by the quality of their underlying kernels, which translate high-level algorithmic semantics into low-level hardware operations. Achieving near-optimal kernels requires expert-level understanding of hardware architectures and programming models, making kernel engineering a critical but notoriously time-consuming and non-scalable process. Recent advances in large language models (LLMs) and LLM-based agents have opened new possibilities for automating kernel generation and optimization. LLMs are well-suited to compress expert-level kernel knowledge that is difficult to formalize, while agentic systems further enable scalable optimization by casting kernel development as an iterative, feedback-driven loop. Rapid progress has been made in this area. However, the field remains fragmented, lacking a systematic perspective for LLM-driven kernel generation. This survey addresses this gap by providing a structured overview of existing approaches, spanning LLM-based approaches and agentic optimization workflows, and systematically compiling the datasets and benchmarks that underpin learning and evaluation in this domain. Moreover, key open challenges and future research directions are further outlined, aiming to establish a comprehensive reference for the next generation of automated kernel optimization. To keep track of this field, we maintain an open-source GitHub repository at https://github.com/flagos-ai/awesome-LLM-driven-kernel-generation.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The performance of modern AI systems is fundamentally constrained by the quality of their underlying kernels, which translate high-level algorithmic semantics into low-level hardware operations.</div>
</details>
</div>
<div class="card">
<div class="title">ShopSimulator: Evaluating and Exploring RL-Driven LLM Agent for Shopping Assistants</div>
<div class="meta-line">Authors: Pei Wang, Yanan Wu, Xiaoshuai Song, Weixun Wang, Gengru Chen, Zhongwen Li, Kezhong Yan, Ken Deng, Qi Liu, Shuaibing Zhao, Shaopan Xiong, Xuepeng Liu, Xuefeng Chen, Wanxi Deng, Wenbo Su, Bo Zheng</div>
<div class="meta-line">First: 2026-01-26T07:24:28+00:00 · Latest: 2026-01-26T07:24:28+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.18225v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.18225v1">PDF</a> · <a href="https://github.com/ShopAgent-Team/ShopSimulator">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large language model (LLM)-based agents are increasingly deployed in e-commerce shopping. To perform thorough, user-tailored product searches, agents should interpret personal preferences, engage in multi-turn dialogues, and ultimately retrieve and discriminate among highly similar products. However, existing research has yet to provide a unified simulation environment that consistently captures all of these aspects, and always focuses solely on evaluation benchmarks without training support. In this paper, we introduce ShopSimulator, a large-scale and challenging Chinese shopping environment. Leveraging ShopSimulator, we evaluate LLMs across diverse scenarios, finding that even the best-performing models achieve less than 40% full-success rate. Error analysis reveals that agents struggle with deep search and product selection in long trajectories, fail to balance the use of personalization cues, and to effectively engage with users. Further training exploration provides practical guidance for overcoming these weaknesses, with the combination of supervised fine-tuning (SFT) and reinforcement learning (RL) yielding significant performance improvements. Code and data will be released at https://github.com/ShopAgent-Team/ShopSimulator.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>商店模拟器：评估与探索强化学习驱动的LLM智能体在购物助手中的应用</div>
<div class="mono" style="margin-top:8px">基于大语言模型（LLM）的智能体在电商购物领域日益普及。为执行全面且用户定制化的产品搜索，智能体需解析个人偏好、进行多轮对话，并最终在高度相似的产品中检索与甄选。然而现有研究尚未提供能统一涵盖这些要素的模拟环境，且始终聚焦于评估基准而缺乏训练支持。本文推出ShopSimulator——一个大规模、高挑战性的中文购物环境。通过该平台，我们在多样化场景中评估LLM性能，发现即使最优模型的全流程成功率也不足40%。错误分析表明：智能体在长轨迹中难以实现深度搜索与产品选择，无法平衡个性化线索的运用，且用户互动效率低下。进一步的训练探索为克服这些缺陷提供了实用方案，其中监督微调（SFT）与强化学习（RL）的结合显著提升了性能。代码与数据将在https://github.com/ShopAgent-Team/ShopSimulator发布。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large language model (LLM)-based agents are increasingly deployed in e-commerce shopping.</div>
</details>
</div>
<div class="card">
<div class="title">DeepPlanning: Benchmarking Long-Horizon Agentic Planning with Verifiable Constraints</div>
<div class="meta-line">Authors: Yinger Zhang, Shutong Jiang, Renhao Li, Jianhong Tu, Yang Su, Lianghao Deng, Xudong Guo, Chenxu Lv, Junyang Lin</div>
<div class="meta-line">First: 2026-01-26T04:43:49+00:00 · Latest: 2026-01-26T04:43:49+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.18137v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.18137v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability. Meanwhile, existing LLM planning benchmarks underrepresent the active information gathering and fine-grained local constraints typical of real-world settings. To address this, we introduce DeepPlanning, a challenging benchmark for practical long-horizon agent planning. It features multi-day travel planning and multi-product shopping tasks that require proactive information acquisition, local constrained reasoning, and global constrained optimization. Evaluations on DeepPlanning show that even frontier agentic LLMs struggle with these problems, highlighting the importance of reliable explicit reasoning patterns and parallel tool use for achieving better effectiveness-efficiency trade-offs. Error analysis further points to promising directions for improving agentic LLMs over long planning horizons. We open-source the code and data to support future research.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">While agent evaluation has shifted toward long-horizon tasks, most benchmarks still emphasize local, step-level reasoning rather than the global constrained optimization (e.g., time and financial budgets) that demands genuine planning ability.</div>
</details>
</div>
<div class="card">
<div class="title">neuralFOMO: Can LLMs Handle Being Second Best? Measuring Envy-Like Preferences in Multi-Agent Settings</div>
<div class="meta-line">Authors: Arnav Ramamoorthy, Shrey Dhorajiya, Ojas Pungalia, Rashi Upadhyay, Abhishek Mishra, Abhiram H, Tejasvi Alladi, Sujan Yenuganti, Dhruv Kumar</div>
<div class="meta-line">First: 2025-12-15T16:17:12+00:00 · Latest: 2026-01-26T04:35:00+00:00</div>
<div class="meta-line">Comments: Under Review</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.13481v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.13481v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Envy shapes competitiveness and cooperation in human groups, yet its role in large language model interactions remains largely unexplored. As LLMs increasingly operate in multi-agent settings, it is important to examine whether they exhibit envy-like preferences under social comparison. We evaluate LLM behavior across two scenarios: (1) a point-allocation game testing sensitivity to relative versus absolute payoff, and (2) comparative evaluations across general and contextual settings. To ground our analysis in psychological theory, we adapt four established psychometric questionnaires spanning general, domain-specific, workplace, and sibling-based envy. Our results reveal heterogeneous envy-like patterns across models and contexts, with some models sacrificing personal gain to reduce a peer&#x27;s advantage, while others prioritize individual maximization. These findings highlight competitive dispositions as a design and safety consideration for multi-agent LLM systems.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by envy&#x27;s impact on human group dynamics and its unexplored role in large language model interactions, this research investigates whether LLMs exhibit envy-like preferences in multi-agent settings. The method adapts four psychometric questionnaires spanning general, domain-specific, workplace, and sibling-based envy, evaluating LLMs through a point-allocation game testing relative versus absolute payoff sensitivity and comparative evaluations across contexts. Key findings reveal heterogeneous envy-like patterns: some models sacrificed personal gain to reduce peers&#x27; advantage, while others prioritized individual maximization, highlighting competitive dispositions as a critical design and safety consideration for multi-agent systems.</div>
<div class="mono" style="margin-top:8px">本研究动机源于大型语言模型（LLM）在多智能体环境中交互日益普遍，但其中嫉妒的作用尚未被探索，旨在探究LLM在社会比较下是否表现出类嫉妒偏好。方法上，通过一个测试相对收益与绝对收益敏感度的点数分配游戏，以及在通用和情境化设置下的比较评估来检验LLM行为，并借鉴四种成熟的心理测量嫉妒问卷为分析提供理论基础。主要实验结果揭示了模型间和情境下存在异质的类嫉妒模式：部分模型会牺牲自身收益以削弱同伴优势，而其他模型则优先个体收益最大化，这突显了竞争倾向作为多智能体LLM系统设计与安全的关键考量因素。</div>
</details>
</div>
<div class="card">
<div class="title">LLMs as Layout Designers: Enhanced Spatial Reasoning for Content-Aware Layout Generation</div>
<div class="meta-line">Authors: Sha Li, Stefano Petrangeli, Yu Shen, Xiang Chen, Naren Ramakrishnan</div>
<div class="meta-line">First: 2025-09-21T03:02:59+00:00 · Latest: 2026-01-25T23:11:38+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.16891v4">Abs</a> · <a href="https://arxiv.org/pdf/2509.16891v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">While Large Language Models (LLMs) have demonstrated impressive reasoning and planning abilities in textual domains and can effectively follow instructions for complex tasks, their ability to understand and manipulate spatial relationships remains limited. Such capabilities are crucial for content-aware graphic layout design, where the goal is to arrange heterogeneous elements onto a canvas so that final design remains visually balanced and structurally feasible. This problem requires precise coordination of placement, alignment, and structural organization of multiple elements within a constrained visual space. To address this limitation, we introduce LaySPA, a reinforcement learning-based framework that augments LLM-based agents with explicit spatial reasoning capabilities for layout design. LaySPA employs hybrid reward signals that jointly capture geometric constraints, structural fidelity, and visual quality, enabling agents to navigate the canvas, model inter-element relationships, and optimize spatial arrangements. Through group-relative policy optimization, the agent generates content-aware layouts that reflect salient regions, respect spatial constraints, and produces an interpretable reasoning trace explaining placement decisions and a structured layout specification. Experimental results show that LaySPA substantially improves the generation of structurally valid and visually appealing layouts, outperforming larger general-purpose LLMs and achieving performance comparable to state-of-the-art specialized layout models.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the limited spatial reasoning capabilities of Large Language Models (LLMs) for content-aware graphic layout design, which requires arranging diverse elements on a canvas while maintaining visual balance and structural feasibility, this work introduces LaySPA. LaySPA is a reinforcement learning framework that enhances LLM-based agents with explicit spatial reasoning, utilizing hybrid reward signals to jointly optimize geometric constraints, structural fidelity, and visual quality, enabling agents to navigate the canvas and model inter-element relationships. Experiments demonstrate that LaySPA significantly improves the generation of structurally valid and visually appealing layouts, outperforming larger general-purpose LLMs and achieving performance comparable to specialized state-of-the-art layout models.</div>
<div class="mono" style="margin-top:8px">针对大语言模型在内容感知图形布局设计中空间推理能力不足的问题——该任务需在画布上协调排列异构元素以保持视觉平衡与结构可行性，本研究提出了LaySPA框架。该方法采用强化学习增强基于大语言模型的智能体，通过融合几何约束、结构保真度和视觉质量的混合奖励信号，使智能体能够导航画布空间并建模元素间关系。实验结果表明，LaySPA显著提升了生成布局的结构有效性和视觉吸引力，性能超越更大规模的通用大语言模型，并达到与专业布局领域先进模型相当的水平。</div>
</details>
</div>
<div class="card">
<div class="title">Automated structural testing of LLM-based agents: methods, framework, and case studies</div>
<div class="meta-line">Authors: Jens Kohl, Otto Kruse, Youssef Mostafa, Andre Luckow, Karsten Schroer, Thomas Riedl, Ryan French, David Katz, Manuel P. Luitz, Tanrajbir Takher, Ken E. Friedl, Céline Laurent-Winter</div>
<div class="meta-line">First: 2026-01-25T11:52:30+00:00 · Latest: 2026-01-25T11:52:30+00:00</div>
<div class="meta-line">Comments: 10 pages, 5 figures. Preprint of an accepted paper at IEEE BigData 2025 (main track). Source code for the introduced methods and framework available at https://github.com/awslabs/generative-ai-toolkit</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.18827v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.18827v1">PDF</a> · <a href="https://github.com/awslabs/generative-ai-toolkit">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">LLM-based agents are rapidly being adopted across diverse domains. Since they interact with users without supervision, they must be tested extensively. Current testing approaches focus on acceptance-level evaluation from the user&#x27;s perspective. While intuitive, these tests require manual evaluation, are difficult to automate, do not facilitate root cause analysis, and incur expensive test environments. In this paper, we present methods to enable structural testing of LLM-based agents. Our approach utilizes traces (based on OpenTelemetry) to capture agent trajectories, employs mocking to enforce reproducible LLM behavior, and adds assertions to automate test verification. This enables testing agent components and interactions at a deeper technical level within automated workflows. We demonstrate how structural testing enables the adaptation of software engineering best practices to agents, including the test automation pyramid, regression testing, test-driven development, and multi-language testing. In representative case studies, we demonstrate automated execution and faster root-cause analysis. Collectively, these methods reduce testing costs and improve agent quality through higher coverage, reusability, and earlier defect detection. We provide an open source reference implementation on GitHub.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the limitations of current acceptance-level testing for LLM-based agents—such as manual evaluation, poor automation, difficulty in root-cause analysis, and high costs—this research introduces methods for automated structural testing. The approach utilizes OpenTelemetry traces to capture agent execution paths, employs mocking to enforce reproducible LLM responses, and integrates assertions for automated verification, enabling deeper technical inspection within workflows. Experimental case studies demonstrate that this structural testing framework facilitates software engineering best practices like test-driven development and regression testing, resulting in automated execution, faster root-cause analysis, reduced testing costs, and improved agent quality through higher coverage and earlier defect detection.</div>
<div class="mono" style="margin-top:8px">基于LLM的智能体在无监督交互场景中广泛应用，亟需通过测试确保可靠性。现有验收级测试方法依赖人工、难以自动化且成本高昂，缺乏根因分析能力。为此，我们提出结构化测试方法：利用OpenTelemetry追踪记录智能体轨迹，通过模拟LLM行为确保可复现性，并采用断言实现自动化验证，从而在自动化流程中实现细粒度组件测试。案例研究表明，该方法支持测试驱动开发与回归测试等软件工程实践，显著加速根因分析，降低测试成本，提高覆盖率和缺陷早期发现率。</div>
</details>
</div>
<div class="card">
<div class="title">Spectral Logit Sculpting: Adaptive Low-Rank Logit Transformation for Controlled Text Generation</div>
<div class="meta-line">Authors: Jin Li, Zhebo Wang, Tianliang Lu, Mohan Li, Wenpeng Xing, Meng Han</div>
<div class="meta-line">Venue: ICASSP 2026</div>
<div class="meta-line">First: 2025-09-19T04:17:46+00:00 · Latest: 2026-01-25T11:14:05+00:00</div>
<div class="meta-line">Comments: Accepted by IEEE ICASSP 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2509.25204v2">Abs</a> · <a href="https://arxiv.org/pdf/2509.25204v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Entropy-based inference methods have gained traction for improving the reliability of Large Language Models (LLMs). However, many existing approaches, such as entropy minimization techniques, suffer from high computational overhead and fail to leverage historical token context effectively. To address these limitations, we propose Spectral Logit Sculpting (SLS), a lightweight inference-time optimization method that dynamically modulates token distributions using spectral and entropic properties of recent logits. SLS maintains a sliding buffer of top-K logits, performs on-the-fly Singular Value Decomposition (SVD) to identify dominant spectral directions, and adaptively rescales logits based on both entropy and logit gap statistics--only activating when uncertainty is high. Without updating any model parameters, SLS effectively sharpens the output distribution while preserving contextual consistency. Experimental results on multiple public benchmarks demonstrate that SLS consistently outperforms existing baseline methods, achieving superior accuracy in mathematical, coding, and scientific reasoning tasks.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Entropy-based inference methods have gained traction for improving the reliability of Large Language Models (LLMs).</div>
</details>
</div>
<div class="card">
<div class="title">Neuro-Symbolic Verification on Instruction Following of LLMs</div>
<div class="meta-line">Authors: Yiming Su, Kunzhao Xu, Yanjie Gao, Fan Yang, Cheng Li, Mao Yang, Tianyin Xu</div>
<div class="meta-line">First: 2026-01-25T11:03:15+00:00 · Latest: 2026-01-25T11:03:15+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.17789v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.17789v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">A fundamental problem of applying Large Language Models (LLMs) to important applications is that LLMs do not always follow instructions, and violations are often hard to observe or check. In LLM-based agentic workflows, such violations can propagate and amplify along reasoning chains, causing task failures and system incidents. This paper presents NSVIF, a neuro-symbolic framework for verifying whether an LLM&#x27;s output follows the instructions used to prompt the LLM. NSVIF is a universal, general-purpose verifier; it makes no assumption about the instruction or the LLM. NSVIF formulates instruction-following verification as a constraint-satisfaction problem by modeling user instructions as constraints. NSVIF models both logical and semantic constraints; constraint solving is done by a unified solver that orchestrates logical reasoning and semantic analysis. To evaluate NSVIF, we develop VIFBENCH, a new benchmark for instruction-following verifiers with fine-grained data labels. Experiments show that NSVIF significantly outperforms LLM-based approaches and provides interpretable feedback. We also show that feedback from NSVIF helps improve LLMs&#x27; instruction-following capability without post-training.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">A fundamental problem of applying Large Language Models (LLMs) to important applications is that LLMs do not always follow instructions, and violations are often hard to observe or check.</div>
</details>
</div>
<div class="card">
<div class="title">Do Reasoning Models Ask Better Questions? A Formal Information-Theoretic Analysis on Multi-Turn LLM Games</div>
<div class="meta-line">Authors: Daniel M. Pedrozo, Telma W. de L. Soares, Bryan L. M. de Oliveira</div>
<div class="meta-line">Venue: AAAI 2026</div>
<div class="meta-line">First: 2026-01-25T06:38:15+00:00 · Latest: 2026-01-25T06:38:15+00:00</div>
<div class="meta-line">Comments: Presented at the NeusymBridge Workshop at AAAI 2026</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.17716v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.17716v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Large Language Models (LLMs) excel at many tasks but still struggle with a critical ability for LLM-based agents: asking good questions for resolving ambiguity in user requests. While prior work has explored information-seeking behavior through word games, existing benchmarks lack comprehensive evaluation frameworks that provide both final and intermediate signals based on Information Gain (IG). Moreover, they rarely provide systematic comparisons between models that use chain-of-thought reasoning and those that do not. We propose a multi-turn dialogue framework that quantitatively measures how effectively LLMs gather information through yes/no questions in a hierarchical knowledge graph environment. Our framework employs a triad of interacting LLM agents that ask questions, answer them, and update the hypothesis space. We adopt IG as the main metric, grounded in Shannon entropy, to assess query effectiveness at each turn and cumulatively. We instantiate our framework in a geographical Guess My City game setting organized in a five-level taxonomy and evaluate multiple LLM variants under fully and partially observable conditions, with and without Chain-of-Thought reasoning. Our experiments demonstrate that, among the evaluated models, the ones with explicit reasoning capabilities achieve higher IG per turn and reach solutions in fewer steps, particularly in partially observable settings. Analysis of reasoning traces reveals that smaller models compensate for limited capacity through more aggressive exploration of candidate questions, while larger models exhibit higher assertiveness in selecting optimal queries, generating candidates with greater potential IG.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Large Language Models (LLMs) excel at many tasks but still struggle with a critical ability for LLM-based agents: asking good questions for resolving ambiguity in user requests.</div>
</details>
</div>
<div class="card">
<div class="title">Bridging Expectation Signals: LLM-Based Experiments and a Behavioral Kalman Filter Framework</div>
<div class="meta-line">Authors: Yu Wang, Xiangchen Liu</div>
<div class="meta-line">First: 2026-01-24T16:56:42+00:00 · Latest: 2026-01-24T16:56:42+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.17527v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.17527v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">As LLMs increasingly function as economic agents, the specific mechanisms LLMs use to update their belief with heterogeneous signals remain opaque. We design experiments and develop a Behavioral Kalman Filter framework to quantify how LLM-based agents update expectations, acting as households or firm CEOs, update expectations when presented with individual and aggregate signals. The results from experiments and model estimation reveal four consistent patterns: (1) agents&#x27; weighting of priors and signals deviates from unity; (2) both household and firm CEO agents place substantially larger weights on individual signals compared to aggregate signals; (3) we identify a significant and negative interaction between concurrent signals, implying that the presence of multiple information sources diminishes the marginal weight assigned to each individual signal; and (4) expectation formation patterns differ significantly between household and firm CEO agents. Finally, we demonstrate that LoRA fine-tuning mitigates, but does not fully eliminate, behavioral biases in LLM expectation formation.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Motivated by the opacity in how LLMs update beliefs as economic agents when receiving heterogeneous signals, this study designs experiments and develops a Behavioral Kalman Filter framework to quantify expectation updating in LLM-based agents acting as households or firm CEOs. The method exposes agents to individual and aggregate signals to measure belief revision patterns. Key experimental results reveal four consistent findings: agents underweight priors and signals relative to Bayesian norms; both agent types strongly favor individual over aggregate signals; concurrent signals exhibit negative interaction, reducing marginal weights per signal; household and CEO agents show distinct expectation formation patterns. Additionally, LoRA fine-tuning reduces but does not eliminate these behavioral biases.</div>
<div class="mono" style="margin-top:8px">本研究针对大型语言模型作为经济代理时更新异质信号信念的机制不透明问题，通过设计实验并建立行为卡尔曼滤波框架，量化了模拟家庭和公司CEO的LLM代理在接收个体与汇总信号时的预期更新行为。实验方法通过向代理呈现不同类型信号来测量信念修正模式。核心实验结果揭示了四个一致规律：代理对先验和信号的加权均偏离贝叶斯标准；家庭和CEO代理均显著更重视个体信号而非汇总信号；并发信号存在负向交互作用，降低各信号的边际权重；家庭与CEO代理的预期形成模式差异显著。研究还表明LoRA微调可减轻但无法完全消除这些行为偏差。</div>
</details>
</div>
<div class="card">
<div class="title">Parameter Efficient Fine Tuning Llama 3.1 for Answering Arabic Legal Questions: A Case Study on Jordanian Laws</div>
<div class="meta-line">Authors: Mohammed Fasha, Bassam Hammo, Bilal Sowan, Husam Barham, Esam Nsour</div>
<div class="meta-line">Venue: 2025 1st International Conference on Computational Intelligence Approaches and Applications (ICCIAA), Amman, Jordan, 2025, pp. 1-5</div>
<div class="meta-line">First: 2026-01-24T08:17:26+00:00 · Latest: 2026-01-24T08:17:26+00:00</div>
<div class="meta-line">Comments: 5 pages, resources at: https://github.com/msfasha/Research-Resources/tree/main/ArabicLegalLLM</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.17364v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.17364v1">PDF</a> · <a href="https://github.com/msfasha/Research-Resources/tree/main/ArabicLegalLLM">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">This study uses Jordanian law as a case study to explore the fine-tuning of the Llama-3.1 large language model for Arabic question-answering. Two versions of the model - Llama-3.1-8B-bnb-4bit and Llama-3.1-8B-Instruct-bnb-4bit - were fine-tuned using parameter-efficient fine-tuning (PEFT) with LoRA adapters and 4-bit quantized models, leveraging the Unsloth framework for accelerated and resource-efficient training. A custom dataset of 6000 legal question-answer pairs was curated from Jordanian laws and formatted into structured prompts. Performance was evaluated using the BLEU and the ROUGE metrics to compare the fine-tuned models to their respective base versions. Results demonstrated improved legal reasoning and accuracy while achieving resource efficiency through quantization and optimized fine-tuning strategies. This work underscores the potential of adapting large language models for Arabic legal domains and highlights effective techniques for fine-tuning domain-specific tasks.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">This study uses Jordanian law as a case study to explore the fine-tuning of the Llama-3.1 large language model for Arabic question-answering.</div>
</details>
</div>
<div class="card">
<div class="title">Mitigating Visual Knowledge Forgetting in MLLM Instruction-tuning via Modality-decoupled Gradient Descent</div>
<div class="meta-line">Authors: Junda Wu, Yuxin Xiong, Xintong Li, Yu Xia, Ruoyu Wang, Yu Wang, Tong Yu, Sungchul Kim, Ryan A. Rossi, Lina Yao, Jingbo Shang, Julian McAuley</div>
<div class="meta-line">First: 2025-02-17T12:26:34+00:00 · Latest: 2026-01-23T23:56:40+00:00</div>
<div class="meta-line">Comments: 9 pages</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2502.11740v2">Abs</a> · <a href="https://arxiv.org/pdf/2502.11740v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Recent MLLMs have shown emerging visual understanding and reasoning abilities after being pre-trained on large-scale multimodal datasets. Unlike pre-training, where MLLMs receive rich visual-text alignment, instruction-tuning is often text-driven with weaker visual supervision, leading to the degradation of pre-trained visual understanding and causing visual forgetting. Existing approaches, such as direct fine-tuning and continual learning methods, fail to explicitly address this issue, often compressing visual representations and prioritizing task alignment over visual retention, which further worsens visual forgetting. To overcome this limitation, we introduce a novel perspective leveraging effective rank to quantify the degradation of visual representation richness, interpreting this degradation through the information bottleneck principle as excessive compression that leads to the degradation of crucial pre-trained visual knowledge. Building on this view, we propose a modality-decoupled gradient descent (MDGD) method that regulates gradient updates to maintain the effective rank of visual representations while mitigating the over-compression effects described by the information bottleneck. By explicitly disentangling the optimization of visual understanding from task-specific alignment, MDGD preserves pre-trained visual knowledge while enabling efficient task adaptation. To enable lightweight instruction-tuning, we further develop a memory-efficient fine-tuning approach using gradient masking, which selectively updates a subset of model parameters to enable parameter-efficient fine-tuning (PEFT), reducing computational overhead while preserving rich visual representations. Extensive experiments across various downstream tasks and backbone MLLMs demonstrate that MDGD effectively mitigates visual forgetting from pre-trained tasks while enabling strong adaptation to new tasks.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Recent MLLMs have shown emerging visual understanding and reasoning abilities after being pre-trained on large-scale multimodal datasets.</div>
</details>
</div>
<div class="card">
<div class="title">Turn-PPO: Turn-Level Advantage Estimation with PPO for Improved Multi-Turn RL in Agentic LLMs</div>
<div class="meta-line">Authors: Junbo Li, Peng Zhou, Rui Meng, Meet P. Vadera, Lihong Li, Yang Li</div>
<div class="meta-line">Venue: EACL 2026</div>
<div class="meta-line">First: 2025-12-18T19:07:25+00:00 · Latest: 2026-01-23T23:39:54+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2512.17008v2">Abs</a> · <a href="https://arxiv.org/pdf/2512.17008v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Reinforcement learning (RL) has re-emerged as a natural approach for training interactive LLM agents in real-world environments. However, directly applying the widely used Group Relative Policy Optimization (GRPO) algorithm to multi-turn tasks exposes notable limitations, particularly in scenarios requiring long-horizon reasoning. To address these challenges, we investigate more stable and effective advantage estimation strategies, especially for multi-turn settings. We first explore Proximal Policy Optimization (PPO) as an alternative and find it to be more robust than GRPO. To further enhance PPO in multi-turn scenarios, we introduce turn-PPO, a variant that operates on a turn-level MDP formulation, as opposed to the commonly used token-level MDP. Our results on the WebShop and Sokoban datasets demonstrate the effectiveness of turn-PPO, both with and without long reasoning components.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>Turn-PPO：基于PPO的回合级优势估计以改进智能大语言模型中的多轮强化学习</div>
<div class="mono" style="margin-top:8px">强化学习（RL）已成为在真实环境中训练交互式大语言模型（LLM）智能体的自然方法。然而，将广泛使用的组相对策略优化（GRPO）算法直接应用于多轮任务时存在显著局限，尤其在需要长程推理的场景中。为应对这些挑战，我们研究了更稳定高效的优势估计策略，特别针对多轮交互场景。我们首先探索近端策略优化（PPO）作为替代方案，发现其鲁棒性优于GRPO。为在多轮场景中进一步提升PPO性能，我们提出turn-PPO变体——该算法基于回合级马尔可夫决策过程（MDP）框架设计，而非常用的词元级MDP。在WebShop和Sokoban数据集上的实验结果表明，无论是否包含长程推理组件，turn-PPO均展现出卓越效能。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Reinforcement learning (RL) has re-emerged as a natural approach for training interactive LLM agents in real-world environments.</div>
</details>
</div>
<div class="card">
<div class="title">LT-Soups: Bridging Head and Tail Classes via Subsampled Model Soups</div>
<div class="meta-line">Authors: Masih Aminbeidokhti, Subhankar Roy, Eric Granger, Elisa Ricci, Marco Pedersoli</div>
<div class="meta-line">Venue: Neurips 2025</div>
<div class="meta-line">First: 2025-11-11T14:15:57+00:00 · Latest: 2026-01-23T23:22:15+00:00</div>
<div class="meta-line">Comments: Neurips 2025</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2511.10683v2">Abs</a> · <a href="https://arxiv.org/pdf/2511.10683v2">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Real-world datasets typically exhibit long-tailed (LT) distributions, where a few head classes dominate and many tail classes are severely underrepresented. While recent work shows that parameter-efficient fine-tuning (PEFT) methods like LoRA and AdaptFormer preserve tail-class performance on foundation models such as CLIP, we find that they do so at the cost of head-class accuracy. We identify the head-tail ratio, the proportion of head to tail classes, as a crucial but overlooked factor influencing this trade-off. Through controlled experiments on CIFAR100 with varying imbalance ratio ($ρ$) and head-tail ratio ($η$), we show that PEFT excels in tail-heavy scenarios but degrades in more balanced and head-heavy distributions. To overcome these limitations, we propose LT-Soups, a two-stage model soups framework designed to generalize across diverse LT regimes. In the first stage, LT-Soups averages models fine-tuned on balanced subsets to reduce head-class bias; in the second, it fine-tunes only the classifier on the full dataset to restore head-class accuracy. Experiments across six benchmark datasets show that LT-Soups achieves superior trade-offs compared to both PEFT and traditional model soups across a wide range of imbalance regimes.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Real-world datasets typically exhibit long-tailed (LT) distributions, where a few head classes dominate and many tail classes are severely underrepresented.</div>
</details>
</div>
<div class="card">
<div class="title">TrojanGYM: A Detector-in-the-Loop LLM for Adaptive RTL Hardware Trojan Insertion</div>
<div class="meta-line">Authors: Saideep Sreekumar, Zeng Wang, Akashdeep Saha, Weihua Xiao, Minghao Shao, Muhammad Shafique, Ozgur Sinanoglu, Ramesh Karri, Johann Knechtel</div>
<div class="meta-line">First: 2026-01-23T21:11:44+00:00 · Latest: 2026-01-23T21:11:44+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.17178v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.17178v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Hardware Trojans (HTs) remain a critical threat because learning-based detectors often overfit to narrow trigger/payload patterns and small, stylized benchmarks. We introduce TrojanGYM, an agentic, LLM-driven framework that automatically curates HT insertions to expose detector blind spots while preserving design correctness. Given high-level HT specifications, a suite of cooperating LLM agents (instantiated with GPT-4, LLaMA-3.3-70B, and Gemini-2.5Pro) proposes and refines RTL modifications that realize diverse triggers and payloads without impacting normal functionality. TrojanGYM implements a feedback-driven benchmark generation loop co-designed with HT detectors, in which constraint-aware syntactic checking and GNN-based HT detectors provide feedback that iteratively refines HT specifications and insertion strategies to better surface detector blind spots. We further propose Robust-GNN4TJ, a new implementation of the GNN4TJ with improved graph extraction, training robustness, and prediction reliability, especially on LLM-generated HT designs. On the most challenging TrojanGYM-generated benchmarks, Robust-GNN4TJ raises HT detection rates from 0% to 60% relative to a prior GNN-based detector. We instantiate TrojanGYM on SRAM, AES-128, and UART designs at RTL level, and show that it systematically produces diverse, functionally correct HTs that reach up to 83.33% evasion rates against modern GNN-based detectors, revealing robustness gaps that are not apparent when these detectors are evaluated solely on existing TrustHub-style benchmarks. Post peer-review, we will release all codes and artifacts.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Hardware Trojans (HTs) remain a critical threat because learning-based detectors often overfit to narrow trigger/payload patterns and small, stylized benchmarks.</div>
</details>
</div>
<div class="card">
<div class="title">Learning to Collaborate: An Orchestrated-Decentralized Framework for Peer-to-Peer LLM Federation</div>
<div class="meta-line">Authors: Inderjeet Singh, Eleonore Vissol-Gaudin, Andikan Otung, Motoyoshi Sekiya</div>
<div class="meta-line">Venue: AAAI 2026</div>
<div class="meta-line">First: 2026-01-23T19:18:43+00:00 · Latest: 2026-01-23T19:18:43+00:00</div>
<div class="meta-line">Comments: Accepted to AAAI 2026. 13 pages, 3 figures, 10 tables. Code available at: https://github.com/FujitsuResearch/knexa-fl</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.17133v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.17133v1">PDF</a> · <a href="https://github.com/FujitsuResearch/knexa-fl">Code1</a> · <a href="https://huggingface.co/huggingface">Code2</a> · <a href="https://huggingface.co/docs/hub/spaces">Code3</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Fine-tuning Large Language Models (LLMs) for specialized domains is constrained by a fundamental challenge: the need for diverse, cross-organizational data conflicts with the principles of data privacy and sovereignty. While Federated Learning (FL) provides a framework for collaboration without raw data exchange, its classic centralized form introduces a single point of failure and remains vulnerable to model inversion attacks. Decentralized FL (DFL) mitigates this risk by removing the central aggregator but typically relies on inefficient, random peer-to-peer (P2P) pairings, forming a collaboration graph that is blind to agent heterogeneity and risks negative transfer. This paper introduces KNEXA-FL, a novel framework for orchestrated decentralization that resolves this trade-off. KNEXA-FL employs a non-aggregating Central Profiler/Matchmaker (CPM) that formulates P2P collaboration as a contextual bandit problem, using a LinUCB algorithm on abstract agent profiles to learn an optimal matchmaking policy. It orchestrates direct knowledge exchange between heterogeneous, PEFT-based LLM agents via secure distillation, without ever accessing the models themselves. Our comprehensive experiments on a challenging code generation task show that KNEXA-FL yields substantial gains, improving Pass@1 by approx. 50% relative to random P2P collaboration. Critically, our orchestrated approach demonstrates stable convergence, in stark contrast to a powerful centralized distillation baseline which suffers from catastrophic performance collapse. Our work establishes adaptive, learning-based orchestration as a foundational principle for building robust and effective decentralized AI ecosystems.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Fine-tuning Large Language Models (LLMs) for specialized domains is constrained by a fundamental challenge: the need for diverse, cross-organizational data conflicts with the principles of data privacy and sovereignty.</div>
</details>
</div>
<div class="card">
<div class="title">Spatial-Agent: Agentic Geo-spatial Reasoning with Scientific Core Concepts</div>
<div class="meta-line">Authors: Riyang Bao, Cheng Yang, Dazhou Yu, Zhexiang Tang, Gengchen Mai, Liang Zhao</div>
<div class="meta-line">First: 2026-01-23T18:33:45+00:00 · Latest: 2026-01-23T18:33:45+00:00</div>
<div class="meta-line">Comments: 15pages, 4 figures</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16965v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16965v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">Geospatial reasoning is essential for real-world applications such as urban analytics, transportation planning, and disaster response. However, existing LLM-based agents often fail at genuine geospatial computation, relying instead on web search or pattern matching while hallucinating spatial relationships. We present Spatial-Agent, an AI agent grounded in foundational theories of spatial information science. Our approach formalizes geo-analytical question answering as a concept transformation problem, where natural-language questions are parsed into executable workflows represented as GeoFlow Graphs -- directed acyclic graphs with nodes corresponding to spatial concepts and edges representing transformations. Drawing on spatial information theory, Spatial-Agent extracts spatial concepts, assigns functional roles with principled ordering constraints, and composes transformation sequences through template-based generation. Extensive experiments on MapEval-API and MapQA benchmarks demonstrate that Spatial-Agent significantly outperforms existing baselines including ReAct and Reflexion, while producing interpretable and executable geospatial workflows.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">Geospatial reasoning is essential for real-world applications such as urban analytics, transportation planning, and disaster response.</div>
</details>
</div>
<div class="card">
<div class="title">Ready Jurist One: Benchmarking Language Agents for Legal Intelligence in Dynamic Environments</div>
<div class="meta-line">Authors: Zheng Jia, Shengbin Yue, Wei Chen, Siyuan Wang, Yidong Liu, Zejun Li, Yun Song, Zhongyu Wei</div>
<div class="meta-line">First: 2025-07-05T13:31:21+00:00 · Latest: 2026-01-23T11:38:39+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2507.04037v4">Abs</a> · <a href="https://arxiv.org/pdf/2507.04037v4">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The gap between static benchmarks and the dynamic nature of real-world legal practice poses a key barrier to advancing legal intelligence. To this end, we introduce J1-ENVS, the first interactive and dynamic legal environment tailored for LLM-based agents. Guided by legal experts, it comprises six representative scenarios from Chinese legal practices across three levels of environmental complexity. We further introduce J1-EVAL, a fine-grained evaluation framework, designed to assess both task performance and procedural compliance across varying levels of legal proficiency. Extensive experiments on 17 LLM agents reveal that, while many models demonstrate solid legal knowledge, they struggle with procedural execution in dynamic settings. Even the SOTA model, GPT-4o, falls short of 60% overall performance. These findings highlight persistent challenges in achieving dynamic legal intelligence and offer valuable insights to guide future research.</div></details>
<details class="detail"><summary>中文标题/摘要</summary>
<div class="mono"><b>标题：</b>预备法务官一号：动态环境中法律智能语言代理的基准测试</div>
<div class="mono" style="margin-top:8px">静态基准测试与现实法律实践动态特性之间的差距，是推进法律智能发展的关键障碍。为此，我们推出首个面向基于LLM代理的交互式动态法律环境J1-ENVS。在法律专家指导下，该环境涵盖中国法律实践中六个代表性场景，分属三个环境复杂度层级。我们进一步提出细粒度评估框架J1-EVAL，旨在评估不同法律专业水平下的任务执行能力与程序合规性。通过对17个LLM代理的广泛实验发现：尽管多数模型展现出扎实的法律知识，但在动态环境中的程序执行方面表现欠佳。即使是SOTA模型GPT-4o，其总体表现也不足60%。这些发现凸显了实现动态法律智能的持续挑战，并为未来研究提供了重要指引。</div>
</details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The gap between static benchmarks and the dynamic nature of real-world legal practice poses a key barrier to advancing legal intelligence.</div>
</details>
</div>
<div class="card">
<div class="title">GRASP: Guided Region-Aware Sparse Prompting for Adapting MLLMs to Remote Sensing</div>
<div class="meta-line">Authors: Qigan Sun, Chaoning Zhang, Jianwei Zhang, Xudong Wang, Jiehui Xie, Pengcheng Zheng, Haoyu Wang, Sungyoung Lee, Chi-lok Andy Tai, Yang Yang, Heng Tao Shen</div>
<div class="meta-line">First: 2026-01-23T10:12:59+00:00 · Latest: 2026-01-23T10:12:59+00:00</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.17089v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.17089v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">In recent years, Multimodal Large Language Models (MLLMs) have made significant progress in visual question answering tasks. However, directly applying existing fine-tuning methods to remote sensing (RS) images often leads to issues such as overfitting on background noise or neglecting target details. This is primarily due to the large-scale variations, sparse target distributions, and complex regional semantic features inherent in RS images. These challenges limit the effectiveness of MLLMs in RS tasks. To address these challenges, we propose a parameter-efficient fine-tuning (PEFT) strategy called Guided Region-Aware Sparse Prompting (GRASP). GRASP introduces spatially structured soft prompts associated with spatial blocks extracted from a frozen visual token grid. Through a question-guided sparse fusion mechanism, GRASP dynamically aggregates task-specific context into a compact global prompt, enabling the model to focus on relevant regions while filtering out background noise. Extensive experiments on multiple RSVQA benchmarks show that GRASP achieves competitive performance compared to existing fine-tuning and prompt-based methods while maintaining high parameter efficiency.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">In recent years, Multimodal Large Language Models (MLLMs) have made significant progress in visual question answering tasks.</div>
</details>
</div>
<div class="card">
<div class="title">LLM is Not All You Need: A Systematic Evaluation of ML vs. Foundation Models for text and image based Medical Classification</div>
<div class="meta-line">Authors: Meet Raval, Tejul Pandit, Dhvani Upadhyay</div>
<div class="meta-line">First: 2026-01-23T08:35:53+00:00 · Latest: 2026-01-23T08:35:53+00:00</div>
<div class="meta-line">Comments: 9 pages, 5 figures, 3 tables, paper accepted in AAIML&#x27;26 conference</div>
<div class="links" style="margin-top:8px"><a href="https://arxiv.org/abs/2601.16549v1">Abs</a> · <a href="https://arxiv.org/pdf/2601.16549v1">PDF</a> · <a href="https://huggingface.co/huggingface">Code1</a> · <a href="https://huggingface.co/docs/hub/spaces">Code2</a></div>
<details class="detail"><summary>Abstract</summary>
<div class="mono">The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification. This work offers a rigorous, unified benchmark by using four publicly available datasets covering text and image modalities (binary and multiclass complexity) that contrasts traditional Machine Learning (ML) with contemporary transformer-based techniques. We evaluated three model classes for each task: Classical ML (LR, LightGBM, ResNet-50), Prompt-Based LLMs/VLMs (Gemini 2.5), and Fine-Tuned PEFT Models (LoRA-adapted Gemma3 variants). All experiments used consistent data splits and aligned metrics. According to our results, traditional machine learning (ML) models set a high standard by consistently achieving the best overall performance across most medical categorization tasks. This was especially true for structured text-based datasets, where the classical models performed exceptionally well. In stark contrast, the LoRA-tuned Gemma variants consistently showed the worst performance across all text and image experiments, failing to generalize from the minimal fine-tuning provided. However, the zero-shot LLM/VLM pipelines (Gemini 2.5) had mixed results; they performed poorly on text-based tasks, but demonstrated competitive performance on the multiclass image task, matching the classical ResNet-50 baseline. These results demonstrate that in many medical categorization scenarios, established machine learning models continue to be the most reliable option. The experiment suggests that foundation models are not universally superior and that the effectiveness of Parameter-Efficient Fine-Tuning (PEFT) is highly dependent on the adaptation strategy, as minimal fine-tuning proved detrimental in this study.</div></details>
<details class="detail"><summary>Summary / 总结</summary>
<div class="mono">The combination of multimodal Vision-Language Models (VLMs) and Large Language Models (LLMs) opens up new possibilities for medical classification.</div>
</details>
</div></div>
    <details style="margin-top:16px" class="detail"><summary>History</summary>
      <div class="history-list"><a href="archive/20260201_1746.html">20260201_1746</a>
<a href="archive/20260201_1152.html">20260201_1152</a>
<a href="archive/20260201_0333.html">20260201_0333</a>
<a href="archive/20260131_0345.html">20260131_0345</a>
<a href="archive/20260130_0341.html">20260130_0341</a>
<a href="archive/20260129_0344.html">20260129_0344</a>
<a href="archive/20260128_0341.html">20260128_0341</a>
<a href="archive/20260127_0338.html">20260127_0338</a>
<a href="archive/20260126_0330.html">20260126_0330</a>
<a href="archive/20260125_0329.html">20260125_0329</a>
<a href="archive/20260124_0337.html">20260124_0337</a>
<a href="archive/20260123_0337.html">20260123_0337</a>
<a href="archive/20260122_0343.html">20260122_0343</a>
<a href="archive/20260121_0424.html">20260121_0424</a>
<a href="archive/20260119_0329.html">20260119_0329</a>
<a href="archive/20260118_0327.html">20260118_0327</a>
<a href="archive/20260117_0332.html">20260117_0332</a>
<a href="archive/20260116_0339.html">20260116_0339</a>
<a href="archive/20260115_0334.html">20260115_0334</a>
<a href="archive/20260114_0333.html">20260114_0333</a>
<a href="archive/20260113_0334.html">20260113_0334</a>
<a href="archive/20260112_0331.html">20260112_0331</a>
<a href="archive/20260111_0329.html">20260111_0329</a>
<a href="archive/20260110_0333.html">20260110_0333</a>
<a href="archive/20260109_0334.html">20260109_0334</a>
<a href="archive/20260108_0335.html">20260108_0335</a>
<a href="archive/20260107_0330.html">20260107_0330</a>
<a href="archive/20260106_0336.html">20260106_0336</a>
<a href="archive/20260105_0328.html">20260105_0328</a>
<a href="archive/20260104_0328.html">20260104_0328</a>
<a href="archive/20260103_0325.html">20260103_0325</a>
<a href="archive/20260102_0339.html">20260102_0339</a>
<a href="archive/20260101_0329.html">20260101_0329</a>
<a href="archive/20251231_0333.html">20251231_0333</a>
<a href="archive/20251230_0332.html">20251230_0332</a>
<a href="archive/20251229_0329.html">20251229_0329</a>
<a href="archive/20251228_0332.html">20251228_0332</a>
<a href="archive/20251227_0329.html">20251227_0329</a>
<a href="archive/20251226_0330.html">20251226_0330</a>
<a href="archive/20251225_0329.html">20251225_0329</a>
<a href="archive/20251224_0331.html">20251224_0331</a>
<a href="archive/20251223_0332.html">20251223_0332</a>
<a href="archive/20251222_0328.html">20251222_0328</a>
<a href="archive/20251221_0329.html">20251221_0329</a>
<a href="archive/20251220_0330.html">20251220_0330</a>
<a href="archive/20251219_0330.html">20251219_0330</a>
<a href="archive/20251218_0345.html">20251218_0345</a>
<a href="archive/20251217_0332.html">20251217_0332</a>
<a href="archive/20251216_0333.html">20251216_0333</a>
<a href="archive/20251215_0333.html">20251215_0333</a>
<a href="archive/20251214_0327.html">20251214_0327</a>
<a href="archive/20251212_0333.html">20251212_0333</a>
<a href="archive/20251211_0331.html">20251211_0331</a>
<a href="archive/20251210_0332.html">20251210_0332</a>
<a href="archive/20251209_0331.html">20251209_0331</a>
<a href="archive/20251208_0328.html">20251208_0328</a>
<a href="archive/20251207_0327.html">20251207_0327</a>
<a href="archive/20251206_0330.html">20251206_0330</a>
<a href="archive/20251205_0331.html">20251205_0331</a>
<a href="archive/20251204_0331.html">20251204_0331</a>
<a href="archive/20251203_0333.html">20251203_0333</a>
<a href="archive/20251202_0335.html">20251202_0335</a>
<a href="archive/20251201_0328.html">20251201_0328</a>
<a href="archive/20251130_0327.html">20251130_0327</a>
<a href="archive/20251129_0328.html">20251129_0328</a>
<a href="archive/20251128_0327.html">20251128_0327</a>
<a href="archive/20251127_0327.html">20251127_0327</a>
<a href="archive/20251126_0329.html">20251126_0329</a>
<a href="archive/20251125_0327.html">20251125_0327</a>
<a href="archive/20251124_0327.html">20251124_0327</a>
<a href="archive/20251123_0326.html">20251123_0326</a>
<a href="archive/20251122_0328.html">20251122_0328</a>
<a href="archive/20251121_0328.html">20251121_0328</a>
<a href="archive/20251120_0329.html">20251120_0329</a>
<a href="archive/20251119_0328.html">20251119_0328</a>
<a href="archive/20251118_0328.html">20251118_0328</a>
<a href="archive/20251117_0326.html">20251117_0326</a>
<a href="archive/20251116_0325.html">20251116_0325</a>
<a href="archive/20251115_0327.html">20251115_0327</a>
<a href="archive/20251114_0328.html">20251114_0328</a>
<a href="archive/20251113_0330.html">20251113_0330</a>
<a href="archive/20251112_0329.html">20251112_0329</a>
<a href="archive/20251111_0328.html">20251111_0328</a>
<a href="archive/20251110_0325.html">20251110_0325</a>
<a href="archive/20251109_0326.html">20251109_0326</a>
<a href="archive/20251108_0328.html">20251108_0328</a>
<a href="archive/20251107_0328.html">20251107_0328</a>
<a href="archive/20251106_0329.html">20251106_0329</a>
<a href="archive/20251105_0326.html">20251105_0326</a>
<a href="archive/20251104_0327.html">20251104_0327</a>
<a href="archive/20251103_0324.html">20251103_0324</a>
<a href="archive/20251102_0326.html">20251102_0326</a>
<a href="archive/20251101_0324.html">20251101_0324</a>
<a href="archive/20251031_0328.html">20251031_0328</a>
<a href="archive/20251030_0330.html">20251030_0330</a>
<a href="archive/20251029_0329.html">20251029_0329</a>
<a href="archive/20251028_0329.html">20251028_0329</a>
<a href="archive/20251027_0322.html">20251027_0322</a>
<a href="archive/20251026_0327.html">20251026_0327</a>
<a href="archive/20251025_0331.html">20251025_0331</a>
<a href="archive/20251024_0329.html">20251024_0329</a>
<a href="archive/20251023_0329.html">20251023_0329</a>
<a href="archive/20251022_0330.html">20251022_0330</a>
<a href="archive/20251021_0331.html">20251021_0331</a>
<a href="archive/20251020_0328.html">20251020_0328</a>
<a href="archive/20251019_0321.html">20251019_0321</a>
<a href="archive/20251018_0327.html">20251018_0327</a>
<a href="archive/20251017_0320.html">20251017_0320</a>
<a href="archive/20251016_0328.html">20251016_0328</a>
<a href="archive/20251015_0328.html">20251015_0328</a>
<a href="archive/20251014_0323.html">20251014_0323</a>
<a href="archive/20251011_0328.html">20251011_0328</a>
<a href="archive/20251010_0330.html">20251010_0330</a>
<a href="archive/20251009_0321.html">20251009_0321</a>
<a href="archive/20251008_0343.html">20251008_0343</a>
<a href="archive/20251007_0353.html">20251007_0353</a>
<a href="archive/20251006_0325.html">20251006_0325</a>
<a href="archive/20251005_0350.html">20251005_0350</a>
<a href="archive/20251004_0352.html">20251004_0352</a>
<a href="archive/20251003_0352.html">20251003_0352</a>
<a href="archive/20251002_0356.html">20251002_0356</a>
<a href="archive/20251001_0321.html">20251001_0321</a>
<a href="archive/20250925_0335.html">20250925_0335</a>
<a href="archive/20250924_0350.html">20250924_0350</a>
<a href="archive/20250923_0348.html">20250923_0348</a>
<a href="archive/20250922_0346.html">20250922_0346</a>
<a href="archive/20250921_0345.html">20250921_0345</a>
<a href="archive/20250920_0342.html">20250920_0342</a>
<a href="archive/20250919_0346.html">20250919_0346</a>
<a href="archive/20250918_0342.html">20250918_0342</a>
<a href="archive/20250917_0336.html">20250917_0336</a>
<a href="archive/20250916_0333.html">20250916_0333</a>
<a href="archive/20250915_0333.html">20250915_0333</a>
<a href="archive/20250914_0328.html">20250914_0328</a>
<a href="archive/20250913_0322.html">20250913_0322</a>
<a href="archive/20250912_0335.html">20250912_0335</a>
<a href="archive/20250911_0337.html">20250911_0337</a>
<a href="archive/20250910_0338.html">20250910_0338</a>
<a href="archive/20250909_0341.html">20250909_0341</a>
<a href="archive/20250908_0342.html">20250908_0342</a>
<a href="archive/20250907_0333.html">20250907_0333</a>
<a href="archive/20250906_0350.html">20250906_0350</a>
<a href="archive/20250905_0319.html">20250905_0319</a>
<a href="archive/20250904_0323.html">20250904_0323</a>
<a href="archive/20250903_0355.html">20250903_0355</a>
<a href="archive/20250902_0325.html">20250902_0325</a>
<a href="archive/20250901_0355.html">20250901_0355</a>
<a href="archive/20250831_0355.html">20250831_0355</a>
<a href="archive/20250830_0356.html">20250830_0356</a>
<a href="archive/20250829_0355.html">20250829_0355</a>
<a href="archive/20250828_0333.html">20250828_0333</a>
<a href="archive/20250827_1654.html">20250827_1654</a>
<a href="archive/20250827_1602.html">20250827_1602</a>
<a href="archive/20250827_1557.html">20250827_1557</a>
<a href="archive/20250827_0320.html">20250827_0320</a>
<a href="archive/20250826_0320.html">20250826_0320</a>
<a href="archive/20250825_1752.html">20250825_1752</a>
<a href="archive/20250825_1709.html">20250825_1709</a>
<a href="archive/20250825_1652.html">20250825_1652</a>
<a href="archive/20250825_1647.html">20250825_1647</a>
<a href="archive/20250825_1645.html">20250825_1645</a>
<a href="archive/20250825_1631.html">20250825_1631</a>
<a href="archive/20250825_1606.html">20250825_1606</a>
<a href="archive/20250825_1559.html">20250825_1559</a>
<a href="archive/20250825_1558.html">20250825_1558</a>
<a href="archive/20250825_1556.html">20250825_1556</a>
<a href="archive/20250825_1531.html">20250825_1531</a>
<a href="archive/20250825_1525.html">20250825_1525</a>
<a href="archive/20250825_1516.html">20250825_1516</a>
<a href="archive/20250825_1450.html">20250825_1450</a>
<a href="archive/20250825_1444.html">20250825_1444</a>
<a href="archive/20250825_1438.html">20250825_1438</a>
<a href="archive/20250825_1414.html">20250825_1414</a>
<a href="archive/20250825_1413.html">20250825_1413</a>
<a href="archive/20250825_1410.html">20250825_1410</a>
<a href="archive/20250825_1408.html">20250825_1408</a>
<a href="archive/20250825_1405.html">20250825_1405</a>
<a href="archive/20250825_1401.html">20250825_1401</a>
<a href="archive/20250825_1355.html">20250825_1355</a>
<a href="archive/20250825_1347.html">20250825_1347</a>
<a href="archive/20250825_1345.html">20250825_1345</a>
<a href="archive/20250825_1344.html">20250825_1344</a>
<a href="archive/20250825_1343.html">20250825_1343</a>
<a href="archive/20250825_1340.html">20250825_1340</a>
<a href="archive/20250825_1339.html">20250825_1339</a>
<a href="archive/20250825_1333.html">20250825_1333</a>
<a href="archive/20250825_1323.html">20250825_1323</a>
<a href="archive/20250825_1317.html">20250825_1317</a>
<a href="archive/20250825_1243.html">20250825_1243</a>
<a href="archive/20250824_0342.html">20250824_0342</a>
<a href="archive/20250823_0343.html">20250823_0343</a>
<a href="archive/20250823_0142.html">20250823_0142</a>
<a href="archive/20250822_2331.html">20250822_2331</a>
<a href="archive/20250822_2308.html">20250822_2308</a>
<a href="archive/20250822_2258.html">20250822_2258</a>
<a href="archive/20250822_2241.html">20250822_2241</a>
<a href="archive/20250822_2228.html">20250822_2228</a>
<a href="archive/20250822_2206.html">20250822_2206</a>
<a href="archive/20250822_2147.html">20250822_2147</a>
<a href="archive/20250822_2111.html">20250822_2111</a>
<a href="archive/20250822_1259.html">20250822_1259</a>
<a href="archive/20250822_1233.html">20250822_1233</a>
<a href="archive/20250822_1229.html">20250822_1229</a>
<a href="archive/20250822_1223.html">20250822_1223</a>
<a href="archive/20250822_1210.html">20250822_1210</a>
<a href="archive/20250822_1201.html">20250822_1201</a>
<a href="archive/20250822_1111.html">20250822_1111</a>
<a href="archive/20250822_1058.html">20250822_1058</a>
<a href="archive/20250822_1052.html">20250822_1052</a>
<a href="archive/20250822_1045.html">20250822_1045</a>
<a href="archive/20250822_0657.html">20250822_0657</a>
<a href="archive/20250822_0553.html">20250822_0553</a></div>
    </details>
    <div class="footer">Generated by arxiv-tracker</div>
  </div>
</body></html>
